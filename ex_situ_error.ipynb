{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex-situ-error.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52393d806ccf41a1a7ad5d5bbea7575f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c000e8a47638441bb483f05376afc646",
              "IPY_MODEL_14f47adbba7e43de84eeb333f7c1db1f",
              "IPY_MODEL_1992fa31a8a14e1ea0b70d5d810fd3ea"
            ],
            "layout": "IPY_MODEL_0550db54580e4f68b0e3636efe2ed15f"
          }
        },
        "c000e8a47638441bb483f05376afc646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8421853411ab4e0d8cfc5a3ff7f6c937",
            "placeholder": "​",
            "style": "IPY_MODEL_231e7ae79e5d4f56a2caa3ab1efc4ef5",
            "value": "100%"
          }
        },
        "14f47adbba7e43de84eeb333f7c1db1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f39c1cc1db84ea3adba42b4419b5984",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82092e58fc1342eea52c31ae50efe824",
            "value": 9912422
          }
        },
        "1992fa31a8a14e1ea0b70d5d810fd3ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14afd8cfc9f84ac48ce798a5e6db77d7",
            "placeholder": "​",
            "style": "IPY_MODEL_5a23bc0274dc41029f49a47a3e5c242b",
            "value": " 9912422/9912422 [00:00&lt;00:00, 150705981.54it/s]"
          }
        },
        "0550db54580e4f68b0e3636efe2ed15f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8421853411ab4e0d8cfc5a3ff7f6c937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "231e7ae79e5d4f56a2caa3ab1efc4ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f39c1cc1db84ea3adba42b4419b5984": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82092e58fc1342eea52c31ae50efe824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14afd8cfc9f84ac48ce798a5e6db77d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a23bc0274dc41029f49a47a3e5c242b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47babf5622054c24acb5928f81c164df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15916ee5eda14c43ad13420fc1534546",
              "IPY_MODEL_465f77d1661f4d1d9afa362446ac729d",
              "IPY_MODEL_dcecac3b663044f5a976ed1ae5ca43c1"
            ],
            "layout": "IPY_MODEL_0f8d5638f445429aaee18807ba98a484"
          }
        },
        "15916ee5eda14c43ad13420fc1534546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e45307963fc34e2ea1d68d963dfcc315",
            "placeholder": "​",
            "style": "IPY_MODEL_acaadb9bda7a434e8a1249648fa947ca",
            "value": "100%"
          }
        },
        "465f77d1661f4d1d9afa362446ac729d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0970eeb34a34250b2e4ce173907b756",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87959a4157ba47abbbc6fb959331bbc6",
            "value": 28881
          }
        },
        "dcecac3b663044f5a976ed1ae5ca43c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2888d31c847244faa121bda6d8d7e113",
            "placeholder": "​",
            "style": "IPY_MODEL_d026d35c16434dff866a74b38f1e004c",
            "value": " 28881/28881 [00:00&lt;00:00, 971697.47it/s]"
          }
        },
        "0f8d5638f445429aaee18807ba98a484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e45307963fc34e2ea1d68d963dfcc315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acaadb9bda7a434e8a1249648fa947ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0970eeb34a34250b2e4ce173907b756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87959a4157ba47abbbc6fb959331bbc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2888d31c847244faa121bda6d8d7e113": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d026d35c16434dff866a74b38f1e004c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6e039cfed914815b3d395a44711fb2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4200c41986384e559b7f5f188d6621f6",
              "IPY_MODEL_c7d207facc904eacba2fcd3fab0f6607",
              "IPY_MODEL_0564eb8fd19f42bb94bfad8e4b09d02b"
            ],
            "layout": "IPY_MODEL_a94aea0377fc45f8a8d1325a0ea205d0"
          }
        },
        "4200c41986384e559b7f5f188d6621f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d94a2c8f371e45d5b56a09e0f8f0f95a",
            "placeholder": "​",
            "style": "IPY_MODEL_258a88bb0892472fa4b75bd5d0e916e4",
            "value": "100%"
          }
        },
        "c7d207facc904eacba2fcd3fab0f6607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3af06b6e2b24ce893576ae11b91715c",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c08c35afff147f58ec2a816d101d80e",
            "value": 1648877
          }
        },
        "0564eb8fd19f42bb94bfad8e4b09d02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06daa50b278f4498b20335d86b0ad90f",
            "placeholder": "​",
            "style": "IPY_MODEL_260bcb47b9f249258cae79807674d1af",
            "value": " 1648877/1648877 [00:00&lt;00:00, 46558491.18it/s]"
          }
        },
        "a94aea0377fc45f8a8d1325a0ea205d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d94a2c8f371e45d5b56a09e0f8f0f95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258a88bb0892472fa4b75bd5d0e916e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3af06b6e2b24ce893576ae11b91715c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c08c35afff147f58ec2a816d101d80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06daa50b278f4498b20335d86b0ad90f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "260bcb47b9f249258cae79807674d1af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "786130b1d6c34921b23b59823a9f3b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b14ef69981ec41c689a671a3447b1921",
              "IPY_MODEL_cf045f6d5fec484d9a74d29ef1bf930e",
              "IPY_MODEL_e0c1f923c76c471c884aed62b330b77f"
            ],
            "layout": "IPY_MODEL_f2910f4db7c44feaa40e65fb3b749ebd"
          }
        },
        "b14ef69981ec41c689a671a3447b1921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d985aa530545a78f805275a9b2437d",
            "placeholder": "​",
            "style": "IPY_MODEL_0835e33a007145d9aebd2e6981e7563e",
            "value": "100%"
          }
        },
        "cf045f6d5fec484d9a74d29ef1bf930e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_996bdb8da15045508cc9125ebbcc2206",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bb1b23805704c04bf0625e1b6e3a796",
            "value": 4542
          }
        },
        "e0c1f923c76c471c884aed62b330b77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2655fc4673f347e197b1788d1f6cd4e8",
            "placeholder": "​",
            "style": "IPY_MODEL_bef089190b044195ad9615b4890eb9aa",
            "value": " 4542/4542 [00:00&lt;00:00, 145851.42it/s]"
          }
        },
        "f2910f4db7c44feaa40e65fb3b749ebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3d985aa530545a78f805275a9b2437d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0835e33a007145d9aebd2e6981e7563e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "996bdb8da15045508cc9125ebbcc2206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bb1b23805704c04bf0625e1b6e3a796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2655fc4673f347e197b1788d1f6cd4e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bef089190b044195ad9615b4890eb9aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet-18 and CIFAR-10"
      ],
      "metadata": {
        "id": "Ql0i5UAMxiGB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NquOAszVJdL"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Some helper functions for PyTorch, including:\n",
        "    - get_mean_and_std: calculate the mean and std value of dataset.\n",
        "    - msr_init: net parameter initialization.\n",
        "    - progress_bar: progress bar mimic xlua.progress.\n",
        "'''\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "def get_mean_and_std(dataset):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2)\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    print('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:,i,:,:].mean()\n",
        "            std[i] += inputs[:,i,:,:].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std\n",
        "\n",
        "def init_params(net):\n",
        "    '''Init layer parameters.'''\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            init.kaiming_normal(m.weight, mode='fan_out')\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            init.constant(m.weight, 1)\n",
        "            init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            init.normal(m.weight, std=1e-3)\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "\n",
        "def format_time(seconds):\n",
        "    days = int(seconds / 3600/24)\n",
        "    seconds = seconds - days*3600*24\n",
        "    hours = int(seconds / 3600)\n",
        "    seconds = seconds - hours*3600\n",
        "    minutes = int(seconds / 60)\n",
        "    seconds = seconds - minutes*60\n",
        "    secondsf = int(seconds)\n",
        "    seconds = seconds - secondsf\n",
        "    millis = int(seconds*1000)\n",
        "\n",
        "    f = ''\n",
        "    i = 1\n",
        "    if days > 0:\n",
        "        f += str(days) + 'D'\n",
        "        i += 1\n",
        "    if hours > 0 and i <= 2:\n",
        "        f += str(hours) + 'h'\n",
        "        i += 1\n",
        "    if minutes > 0 and i <= 2:\n",
        "        f += str(minutes) + 'm'\n",
        "        i += 1\n",
        "    if secondsf > 0 and i <= 2:\n",
        "        f += str(secondsf) + 's'\n",
        "        i += 1\n",
        "    if millis > 0 and i <= 2:\n",
        "        f += str(millis) + 'ms'\n",
        "        i += 1\n",
        "    if f == '':\n",
        "        f = '0ms'\n",
        "    return f"
      ],
      "metadata": {
        "id": "NmQGc57lWeHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import csv\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Model\n",
        "print('==> Building model..')\n",
        "# net = VGG('VGG19')\n",
        "net = ResNet18()\n",
        "# net = PreActResNet18()\n",
        "# net = GoogLeNet()\n",
        "# net = DenseNet121()\n",
        "# net = ResNeXt29_2x64d()\n",
        "# net = MobileNet()\n",
        "#net = MobileNetV2()\n",
        "# net = DPN92()\n",
        "# net = ShuffleNetG2()\n",
        "# net = SENet18()\n",
        "# net = ShuffleNetV2(1)\n",
        "# net = EfficientNetB0()\n",
        "# net = RegNetX_200MF()\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        if batch_idx % 50 == 0:\n",
        "          with open('log_baseline_train.csv', 'a') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([batch_idx + epoch * 400, train_loss/(batch_idx+1), correct/total])\n",
        "          print(\"Epoch\", epoch, 'iteration',batch_idx, 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                        % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            if batch_idx % 1000 == 0:\n",
        "              with open('log_baseline_test.csv', 'a') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([batch_idx + epoch * 100, test_loss/(batch_idx+1), correct/total])\n",
        "              print(\"Epoch\", epoch, 'iteration',batch_idx, 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                          % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "\n",
        "with open('log_baseline_train.csv', 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"iteration\", \"train_loss\", \"train_acc\"])\n",
        "\n",
        "with open('log_baseline_test.csv', 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"iteration\", \"test_loss\", \"test_acc\"])\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+35):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sv958L3YWgsl",
        "outputId": "88ca5142-9a94-4fb8-8a4e-00c4aa9f9806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==> Building model..\n",
            "\n",
            "Epoch: 0\n",
            "Epoch 0 iteration 0 Loss: 2.339 | Acc: 15.625% (20/128)\n",
            "Epoch 0 iteration 50 Loss: 2.111 | Acc: 21.661% (1414/6528)\n",
            "Epoch 0 iteration 100 Loss: 1.956 | Acc: 27.599% (3568/12928)\n",
            "Epoch 0 iteration 150 Loss: 1.852 | Acc: 31.188% (6028/19328)\n",
            "Epoch 0 iteration 200 Loss: 1.780 | Acc: 33.745% (8682/25728)\n",
            "Epoch 0 iteration 250 Loss: 1.725 | Acc: 35.825% (11510/32128)\n",
            "Epoch 0 iteration 300 Loss: 1.680 | Acc: 37.689% (14521/38528)\n",
            "Epoch 0 iteration 350 Loss: 1.637 | Acc: 39.352% (17680/44928)\n",
            "Epoch 0 iteration 0 Loss: 0.752 | Acc: 100.000% (1/1)\n",
            "Epoch 0 iteration 1000 Loss: 1.343 | Acc: 51.948% (520/1001)\n",
            "Epoch 0 iteration 2000 Loss: 1.365 | Acc: 49.775% (996/2001)\n",
            "Epoch 0 iteration 3000 Loss: 1.365 | Acc: 49.450% (1484/3001)\n",
            "Epoch 0 iteration 4000 Loss: 1.362 | Acc: 49.463% (1979/4001)\n",
            "Epoch 0 iteration 5000 Loss: 1.357 | Acc: 50.190% (2510/5001)\n",
            "Epoch 0 iteration 6000 Loss: 1.356 | Acc: 50.475% (3029/6001)\n",
            "Epoch 0 iteration 7000 Loss: 1.362 | Acc: 50.107% (3508/7001)\n",
            "Epoch 0 iteration 8000 Loss: 1.352 | Acc: 50.544% (4044/8001)\n",
            "Epoch 0 iteration 9000 Loss: 1.356 | Acc: 50.539% (4549/9001)\n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            "Epoch 1 iteration 0 Loss: 1.336 | Acc: 53.906% (69/128)\n",
            "Epoch 1 iteration 50 Loss: 1.308 | Acc: 52.941% (3456/6528)\n",
            "Epoch 1 iteration 100 Loss: 1.295 | Acc: 53.156% (6872/12928)\n",
            "Epoch 1 iteration 150 Loss: 1.283 | Acc: 53.611% (10362/19328)\n",
            "Epoch 1 iteration 200 Loss: 1.265 | Acc: 54.307% (13972/25728)\n",
            "Epoch 1 iteration 250 Loss: 1.249 | Acc: 54.977% (17663/32128)\n",
            "Epoch 1 iteration 300 Loss: 1.235 | Acc: 55.484% (21377/38528)\n",
            "Epoch 1 iteration 350 Loss: 1.216 | Acc: 56.083% (25197/44928)\n",
            "Epoch 1 iteration 0 Loss: 0.333 | Acc: 100.000% (1/1)\n",
            "Epoch 1 iteration 1000 Loss: 1.197 | Acc: 57.742% (578/1001)\n",
            "Epoch 1 iteration 2000 Loss: 1.177 | Acc: 59.320% (1187/2001)\n",
            "Epoch 1 iteration 3000 Loss: 1.194 | Acc: 58.614% (1759/3001)\n",
            "Epoch 1 iteration 4000 Loss: 1.197 | Acc: 58.510% (2341/4001)\n",
            "Epoch 1 iteration 5000 Loss: 1.191 | Acc: 58.968% (2949/5001)\n",
            "Epoch 1 iteration 6000 Loss: 1.204 | Acc: 58.557% (3514/6001)\n",
            "Epoch 1 iteration 7000 Loss: 1.208 | Acc: 58.277% (4080/7001)\n",
            "Epoch 1 iteration 8000 Loss: 1.204 | Acc: 58.255% (4661/8001)\n",
            "Epoch 1 iteration 9000 Loss: 1.201 | Acc: 58.338% (5251/9001)\n",
            "Saving..\n",
            "\n",
            "Epoch: 2\n",
            "Epoch 2 iteration 0 Loss: 0.963 | Acc: 67.969% (87/128)\n",
            "Epoch 2 iteration 50 Loss: 1.050 | Acc: 62.898% (4106/6528)\n",
            "Epoch 2 iteration 100 Loss: 1.046 | Acc: 62.624% (8096/12928)\n",
            "Epoch 2 iteration 150 Loss: 1.042 | Acc: 62.717% (12122/19328)\n",
            "Epoch 2 iteration 200 Loss: 1.032 | Acc: 63.001% (16209/25728)\n",
            "Epoch 2 iteration 250 Loss: 1.019 | Acc: 63.586% (20429/32128)\n",
            "Epoch 2 iteration 300 Loss: 1.009 | Acc: 63.992% (24655/38528)\n",
            "Epoch 2 iteration 350 Loss: 1.000 | Acc: 64.258% (28870/44928)\n",
            "Epoch 2 iteration 0 Loss: 0.352 | Acc: 100.000% (1/1)\n",
            "Epoch 2 iteration 1000 Loss: 0.894 | Acc: 68.432% (685/1001)\n",
            "Epoch 2 iteration 2000 Loss: 0.882 | Acc: 68.116% (1363/2001)\n",
            "Epoch 2 iteration 3000 Loss: 0.895 | Acc: 67.611% (2029/3001)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-e2cb48f5d3bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-e2cb48f5d3bb>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36manswer_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    740\u001b[0m         raise ValueError(\n\u001b[1;32m    741\u001b[0m             \"Authkey must be bytes, not {0!s}\".format(type(authkey)))\n\u001b[0;32m--> 742\u001b[0;31m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHALLENGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message = %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), \"/content/model5.pth\")"
      ],
      "metadata": {
        "id": "MBZ97rKnd-Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crossbar"
      ],
      "metadata": {
        "id": "vR7xLuJWeIP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "crossbar.py\n",
        "Louis Primeau\n",
        "University of Toronto Department of Electrical and Computer Engineering\n",
        "louis.primeau@mail.utoronto.ca\n",
        "July 29th 2020\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import itertools\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import savemat\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import math\n",
        "from scipy.io import savemat\n",
        "\n",
        "# Implements scipy's minmax scaler except just between 0 and 1 for torch Tensors.\n",
        "# Taken from a ptrblck post on the PyTorch forums. Love that dude.\n",
        "class MinMaxScaler(object):\n",
        "    def __call__(self, tensor):\n",
        "        self.scale = 1.0 / (tensor.max(dim=1, keepdim=True)[0] - tensor.min(dim=1, keepdim=True)[0])\n",
        "        self.min = tensor.min(dim=1, keepdim=True)[0]\n",
        "        tensor.sub_(self.min).mul_(self.scale)\n",
        "        return tensor\n",
        "    def inverse_transform(self, tensor):\n",
        "        tensor.div_(self.scale).add_(self.min)\n",
        "        return tensor\n"
      ],
      "metadata": {
        "id": "Gvd10zq6eJ-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ticket:\n",
        "    def __init__(self, row, col, m_rows, m_cols, matrix, mat_scale_factor, crossbar, uvect, decode, inputres, outputres):\n",
        "        self.row, self.col = row, col\n",
        "        self.m_rows, self.m_cols = m_rows, m_cols\n",
        "        self.crossbar = crossbar\n",
        "        self.mat_scale_factor = mat_scale_factor\n",
        "        self.matrix = matrix\n",
        "        self.uvect = uvect\n",
        "        self.inputres = inputres\n",
        "        self.adcres = outputres\n",
        "        self.decode = torch.matmul(self.uvect.t(),self.matrix)\n",
        "\n",
        "    def prep_vector(self, vector, v_bits):\n",
        "\n",
        "        # Scale vector to [0, 2^v_bits]\n",
        "        vect_min = torch.min(vector)\n",
        "        vector = vector - vect_min        \n",
        "        vect_scale_factor = torch.max(vector) / (2**v_bits - 1)\n",
        "        vector = vector / vect_scale_factor if vect_scale_factor != 0.0 else vector\n",
        "\n",
        "        # decompose vector by bit\n",
        "        bit_vector = torch.zeros(vector.size(0),v_bits)\n",
        "        bin2s = lambda x : ''.join(reversed( [str((int(x) >> i) & 1) for i in range(v_bits)] ) )\n",
        "        for j in range(vector.size(0)):\n",
        "            bit_vector[j,:] = torch.Tensor([float(i) for i in list(bin2s(vector[j]))])\n",
        "        bit_vector *= self.crossbar.V\n",
        "        \n",
        "        # Pad bit vector with unselected voltages\n",
        "        pad_vector = torch.zeros(self.crossbar.size[0], v_bits)\n",
        "        \n",
        "        pad_vector[self.row:self.row + self.m_rows,:] = bit_vector\n",
        "\n",
        "        return pad_vector, vect_scale_factor, vect_min\n",
        "\n",
        "    def vmm(self, vector):\n",
        "        # Baseline VMM operation without CODEX\n",
        "        v_bits = self.inputres\n",
        "        assert vector.size(1) == 1, \"vector wrong shape\"\n",
        "\n",
        "        crossbar = self.crossbar\n",
        "        # Rescale vector and convert to bits.\n",
        "        pad_vector, vect_scale_factor, vect_min = self.prep_vector(vector, v_bits)\n",
        "\n",
        "        rW = self.crossbar.W[0:(self.matrix.shape[0]),0:(2*self.matrix.shape[1])]\n",
        "        rW = rW[:,1::2] - rW[:,0::2]\n",
        "\n",
        "        # Perform crossbar VMM\n",
        "        rV = torch.transpose(pad_vector[0:vector.size(0)],0,1)\n",
        "        rout = torch.matmul(rV, rW)\n",
        "\n",
        "        # Round rout to input ADC resolution     \n",
        "        rout_scale_factor = torch.max(rout) / (2**self.adcres - 1)\n",
        "        rout = rout / rout_scale_factor\n",
        "        rout = torch.round(rout)\n",
        "        rout = rout * rout_scale_factor\n",
        "\n",
        "        # Add binary outputs\n",
        "        for i in range(rout.size(0)):\n",
        "            rout[i] *= 2**(v_bits - i - 1)\n",
        "        rout = torch.sum(rout, axis=0)\n",
        "\n",
        "        # Rescale binary outputs\n",
        "        rout = (rout / crossbar.V * vect_scale_factor*self.mat_scale_factor) / 1.5131 + torch.sum(vect_min*self.matrix,axis=0)\n",
        "        return rout.view(-1,1)\n",
        "    \n",
        "    def CODEXvmm(self, xvector):\n",
        "        # CODEX VMM operation\n",
        "        assert xvector.size(1) == 1, \"vector wrong shape\"\n",
        "        v_bits=self.inputres\n",
        "        crossbar = self.crossbar\n",
        "\n",
        "        #Add encoding vector u to x\n",
        "        vector = xvector + self.uvect\n",
        "        pad_vector, vect_scale_factor, vect_min = self.prep_vector(vector, v_bits+1)\n",
        "\n",
        "        rW = self.crossbar.W[0:(self.matrix.shape[0]),0:(2*self.matrix.shape[1])]\n",
        "        rW = rW[:,1::2] - rW[:,0::2]\n",
        "\n",
        "        rV = torch.transpose(pad_vector[0:vector.size(0)],0,1)\n",
        "        # The rout on the line below this comment contains \n",
        "        # the raw output currents that the ADC will receive.\n",
        "        rout = torch.matmul(rV, rW)\n",
        "\n",
        "        # Round rout to input ADC resolution     \n",
        "        rout_scale_factor = torch.max(rout) / (2**self.adcres - 1)\n",
        "        rout = rout / rout_scale_factor\n",
        "        rout = torch.round(rout)\n",
        "        rout = rout * rout_scale_factor\n",
        "\n",
        "        for i in range(rout.size(0)):\n",
        "            rout[i] *= 2**(v_bits - i - 1)\n",
        "        rout = torch.sum(rout, axis=0)\n",
        "        rout = 2*(rout / crossbar.V * vect_scale_factor*self.mat_scale_factor) / 1.5231 + torch.sum(vect_min*self.matrix,axis=0)\n",
        "        rout = rout - self.decode\n",
        "        return rout.view(-1,1)     \n",
        "\n",
        "    def modified_CODEXvmm(self, xvector):\n",
        "        # CODEX VMM operation\n",
        "        assert xvector.size(1) == 1, \"vector wrong shape\"\n",
        "        v_bits=self.inputres\n",
        "        crossbar = self.crossbar\n",
        "\n",
        "        #Add encoding vector u to x\n",
        "        vector = xvector + self.uvect\n",
        "        pad_vector, vect_scale_factor, vect_min = self.prep_vector(vector, v_bits+1)\n",
        "\n",
        "        rW = self.crossbar.W[0:(self.matrix.shape[0]),0:(2*self.matrix.shape[1])]\n",
        "        rW = rW[:,1::2] - rW[:,0::2]\n",
        "\n",
        "        rV = torch.transpose(pad_vector[0:vector.size(0)],0,1)\n",
        "        # The rout on the line below this comment contains \n",
        "        # the raw output currents that the ADC will receive.\n",
        "        rout = torch.matmul(rV, rW)\n",
        "\n",
        "        # Round rout to input ADC resolution     \n",
        "        rout_scale_factor = torch.max(rout) / (2**self.adcres - 1)\n",
        "        rout = rout / rout_scale_factor\n",
        "        rout = torch.round(rout)\n",
        "        rout = rout * rout_scale_factor\n",
        "\n",
        "        for i in range(rout.size(0)):\n",
        "            rout[i] *= 2**(v_bits - i - 1)\n",
        "        rout = torch.sum(rout, axis=0)\n",
        "        rout = 2*(rout / crossbar.V * vect_scale_factor*self.mat_scale_factor) / 1.5231 + torch.sum(vect_min*self.matrix,axis=0)\n",
        "        \n",
        "        # do not decode except during inference\n",
        "        # rout = rout - self.decode \n",
        "        return rout.view(-1,1)     "
      ],
      "metadata": {
        "id": "WF0SYl0SeN3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import random\n",
        "import copy\n",
        "\n",
        "class linear(torch.autograd.Function):\n",
        "    #From Louis: Custom pytorch autograd function for crossbar VMM operation\n",
        "    @staticmethod\n",
        "    def forward(ctx, ticket, x, W, b):\n",
        "        ctx.save_for_backward(x, W, b)\n",
        "        return ticket.CODEXvmm(x) + b\n",
        "        \n",
        "    @staticmethod\n",
        "    def backward(ctx, dx):\n",
        "        x, W, b = ctx.saved_tensors\n",
        "        grad_input = W.t().mm(dx)\n",
        "        grad_weight = dx.mm(x.t())\n",
        "        grad_bias = dx\n",
        "        return (None, grad_input, grad_weight, grad_bias)\n",
        "\n",
        "class Linear(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size, cb,uvect):\n",
        "        super(Linear, self).__init__()\n",
        "        self.W = torch.nn.parameter.Parameter(torch.rand(output_size, input_size))\n",
        "        self.b = torch.nn.parameter.Parameter(torch.rand(output_size, 1))\n",
        "        self.cb = cb\n",
        "\n",
        "        #Instantiate Linear layer with pool of random encoding vectors to sample from\n",
        "        self.uvectlist = uvect\n",
        "        self.uvectidx = 0\n",
        "        # Decoding vector is calculated ideally here off-chip, but calculating decoding vector on-chip is also possible\n",
        "        self.decode = torch.matmul(self.uvectlist[self.uvectidx].t(),torch.transpose(self.W,0,1)).detach().clone()\n",
        "        self.ticket = cb.register_linear(torch.transpose(self.W,0,1),self.uvectlist[self.uvectidx],self.decode)\n",
        "        self.f = linear()\n",
        "        self.cbon = False\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.f.apply(self.ticket, x, self.W, self.b) if self.cbon else self.W.matmul(x) + self.b\n",
        "\n",
        "    def remap(self):\n",
        "        #Should call the remap crossbar function after 1 or a couple update steps \n",
        "        self.cb.clear()\n",
        "        self.ticket = self.cb.register_linear(torch.transpose(self.W,0,1),self.uvectlist[self.uvectidx],self.decode)\n",
        "\n",
        "    def update_decode(self):\n",
        "        #Update decoding vector by updating U*G. \n",
        "        self.decode = torch.matmul(self.uvectlist[self.uvectidx].t(),torch.transpose(self.W,0,1)).detach().clone()\n",
        "\n",
        "    def resample(self):\n",
        "        #Sample random new uvector from provided uvectlist\n",
        "        self.cb.clear()\n",
        "        self.uvectidx = random.randint(0, len(uvectlist)-1)\n",
        "        self.ticket = self.cb.register_linear(torch.transpose(self.W,0,1),self.uvectlist[self.uvectidx],self.decode)\n",
        "    \n",
        "    def use_cb(self, state):\n",
        "        self.cbon = state\n"
      ],
      "metadata": {
        "id": "C9A844rEePiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Key Idea is that CODEX allows us to use higher ADC inpt resolution by\n",
        "# Reducing the ADC sensing range.\n",
        "device_params = {\"Vdd\": 1.8,\n",
        "                 \"r_wl\": 20,\n",
        "                 \"r_bl\": 20,\n",
        "                 \"m\": 600,\n",
        "                 \"n\": 600,\n",
        "                 \"r_on_mean\": 1e4,\n",
        "                 \"r_on_stddev\": 1e3,\n",
        "                 \"r_off_mean\": 1e5,\n",
        "                 \"r_off_stddev\": 1e4,\n",
        "                 \"dac_resolution\": 5,\n",
        "                 \"adc_resolution\": 8.3,\n",
        "                 \"device_resolution\": 6,\n",
        "                 \"bias_scheme\": 1/3,\n",
        "                 \"tile_rows\": 4,\n",
        "                 \"tile_cols\": 4,\n",
        "                 \"r_cmos_line\": 600,\n",
        "                 \"r_cmos_transistor\": 20, \n",
        "                 \"p_stuck_on\": 0.01,\n",
        "                 \"p_stuck_off\": 0.01}\n",
        "\n",
        "\n",
        "class crossbar:\n",
        "    def __init__(self, device_params):\n",
        "  \n",
        "        # Power Supply Voltage\n",
        "        self.V = device_params[\"Vdd\"]\n",
        "\n",
        "        # DAC resolution\n",
        "        self.input_resolution = device_params[\"dac_resolution\"]\n",
        "        self.output_resolution = device_params[\"adc_resolution\"]\n",
        "\n",
        "        # Wordline Resistance \n",
        "        self.r_wl = torch.Tensor((device_params[\"r_wl\"],))\n",
        "        # Bitline Resistance\n",
        "        self.r_bl = torch.Tensor((device_params[\"r_bl\"],))\n",
        "\n",
        "        # Number of rows, columns\n",
        "        self.size = device_params[\"m\"], device_params[\"n\"]\n",
        "\n",
        "        # High resistance state\n",
        "        self.g_on = 1 / torch.normal(device_params[\"r_on_mean\"], device_params[\"r_on_stddev\"], size=self.size)\n",
        "        #self.g_on = (1 / device_params[\"r_on_mean\"]) * torch.ones(self.size)\n",
        "        \n",
        "        # Low Resistance state\n",
        "        self.g_off = 1 / torch.normal(device_params[\"r_off_mean\"], device_params[\"r_off_stddev\"], size=self.size)\n",
        "        #self.g_off = (1 / device_params[\"r_off_mean\"]) * torch.ones(self.size)\n",
        "        \n",
        "        self.g_wl = torch.Tensor((1 / device_params[\"r_wl\"],))\n",
        "        self.g_bl = torch.Tensor((1 / device_params[\"r_bl\"],))\n",
        "        \n",
        "        # Resolution\n",
        "        self.resolution = device_params[\"device_resolution\"]\n",
        "        # Conductance tensor, m x n x 2**resolution        \n",
        "\n",
        "        # 2**self.resolution - 1 so that there's a conductance state in the middle.\n",
        "        self.conductance_states = torch.cat([torch.cat([torch.linspace(self.g_off[i,j], self.g_on[i,j],2**self.resolution - 1).unsqueeze(0)\n",
        "                                                        for j in range(self.size[1])],dim=0).unsqueeze(0)\n",
        "                                             for i in range(self.size[0])],dim=0)\n",
        "\n",
        "        # Bias Scheme\n",
        "        self.bias_voltage = self.V * device_params[\"bias_scheme\"]\n",
        "        \n",
        "        # Tile size (1x1 = 1T1R, nxm = passive, etc.)\n",
        "        self.tile_rows = device_params[\"tile_rows\"]\n",
        "        self.tile_cols = device_params[\"tile_cols\"]\n",
        "        assert self.size[0] % self.tile_rows == 0, \"tile size does not divide crossbar size in row direction\"\n",
        "        assert self.size[1] % self.tile_cols == 0, \"tile size does not divide crossbar size in col direction\"\n",
        "        \n",
        "        # Resistance of CMOS lines\n",
        "        self.r_cmos_line = device_params[\"r_cmos_line\"]\n",
        "\n",
        "        # Conductance Matrix; initialize each memristor at the on resstance\n",
        "        self.W = torch.ones(self.size) * self.g_on\n",
        "\n",
        "        # Stuck-on & stuck-on device nonideality \n",
        "        self.p_stuck_on = device_params[\"p_stuck_on\"]\n",
        "        self.p_stuck_off = device_params[\"p_stuck_off\"]\n",
        "        self.devicefaults = False\n",
        "\n",
        "        self.mapped = []\n",
        "        \n",
        "        self.saved_tiles = {}\n",
        "        \n",
        "    def apply_stuck(self, p_stuck_on, p_stuck_off):\n",
        "\n",
        "        state_dist = torch.distributions.categorical.Categorical(probs=torch.Tensor([p_stuck_on, p_stuck_off, 1 - p_stuck_on - p_stuck_off]))\n",
        "        state_mask = state_dist.sample(self.size)\n",
        "\n",
        "        self.W[state_mask == 0] = self.g_off[state_mask==0]\n",
        "        self.W[state_mask == 1] = self.g_on[state_mask==1]\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def map(self, matrix):\n",
        "        assert not(matrix.size(0) > self.size[0] or matrix.size(1)*2 > self.size[1]), \"input too large\"\n",
        "        midpoint = self.conductance_states.size(2) // 2\n",
        "        \n",
        "        for i in range(matrix.size(0)):\n",
        "            for j in range(matrix.size(1)):\n",
        "\n",
        "                shifted = self.conductance_states[i,j] - self.conductance_states[i,j,midpoint]\n",
        "                idx = torch.min(torch.abs(shifted - matrix[i,j]), dim=0)[1]    \n",
        "\n",
        "                self.W[i,2*j+1] = self.conductance_states[i,j,idx]\n",
        "                self.W[i,2*j] = self.conductance_states[i,j,midpoint-(idx-midpoint)]\n",
        "\n",
        "    def solve(self, voltage):\n",
        "        output = torch.zeros((voltage.size(1), self.size[1]))\n",
        "        for i in range(self.size[0] // self.tile_rows):\n",
        "            for j in range(self.size[1] // self.tile_cols):\n",
        "                for k in range(voltage.size(1)):\n",
        "                    coords = (i*self.tile_rows, (i+1)*self.tile_rows, j*self.tile_cols, (j+1)*self.tile_rows)\n",
        "                    vect = voltage[i*self.tile_rows:(i+1)*self.tile_rows,k]\n",
        "                    solution = self.circuit_solve(coords, vect, torch.zeros(self.size[1]), torch.ones(self.size[1]), torch.zeros(self.size[0]))\n",
        "                    output[k] += torch.cat((torch.zeros(j*self.tile_cols), solution, torch.zeros((self.size[1] // self.tile_cols - j - 1) * self.tile_cols)))\n",
        "        return output\n",
        "\n",
        "    \"\"\"\n",
        "    A Comprehensive Crossbar Array Model With Solutions for Line Resistance and Nonlinear Device Characteristics\n",
        "    An Chen\n",
        "    IEEE TRANSACTIONS ON ELECTRON DEVICES, VOL. 60, NO. 4, APRIL 2013\n",
        "    \"\"\"\n",
        "    \n",
        "    def hash_M(self, a, b, c, d):\n",
        "        return str(a) + \"_\" + str(b) + \"_\" + str(c) + \"_\" + str(d)\n",
        "    \n",
        "    def make_M(self, a, b, c, d):\n",
        "        \n",
        "        conductances = self.W[a:b,c:d]\n",
        "        g_wl, g_bl = self.g_wl, self.g_bl\n",
        "        g_s_wl_in, g_s_wl_out = torch.ones(self.tile_rows) * 1, torch.ones(self.tile_rows) * 1e-9\n",
        "        g_s_bl_in, g_s_bl_out = torch.ones(self.tile_rows) * 1e-9, torch.ones(self.tile_rows) * 1\n",
        "        m, n = self.tile_rows, self.tile_cols\n",
        "        \n",
        "        A = torch.block_diag(*tuple(torch.diag(conductances[i,:])\n",
        "                          + torch.diag(torch.cat((g_wl, g_wl * 2 * torch.ones(n-2), g_wl)))\n",
        "                          + torch.diag(g_wl * -1 *torch.ones(n-1), diagonal = 1)\n",
        "                          + torch.diag(g_wl * -1 *torch.ones(n-1), diagonal = -1)\n",
        "                          + torch.diag(torch.cat((g_s_wl_in[i].view(1), torch.zeros(n - 2), g_s_wl_out[i].view(1))))\n",
        "                                   for i in range(m)))\n",
        "\n",
        "        B = torch.block_diag(*tuple(-torch.diag(conductances[i,:]) for i in range(m)))\n",
        "        \n",
        "        def makec(j):\n",
        "            c = torch.zeros(m, m*n)\n",
        "            for i in range(m):\n",
        "                c[i,n*(i) + j] = conductances[i,j]\n",
        "            return c\n",
        "  \n",
        "        C = torch.cat([makec(j) for j in range(n)],dim=0)\n",
        "        \n",
        "        def maked(j):\n",
        "            d = torch.zeros(m, m*n)\n",
        "\n",
        "            def c(k): \n",
        "                return(k - 1)\n",
        "            \n",
        "            i = 1\n",
        "            d[c(i),c(j)] = -g_s_bl_in[c(j)] - g_bl - conductances[c(i),c(j)]\n",
        "            d[c(i), n*i + c(j)] = g_bl\n",
        "\n",
        "            i = m\n",
        "            d[c(i), n*(i-2) + c(j)] = g_bl\n",
        "            d[c(i), n*(i-1) + c(j)] = -g_s_bl_out[c(j)] - conductances[c(i),c(j)] - g_bl\n",
        "\n",
        "            for i in range(2, m):\n",
        "                d[c(i), n*(i-2) + c(j)] = g_bl\n",
        "                d[c(i), n*(i-1) + c(j)] = -g_bl - conductances[c(i),c(j)] - g_bl\n",
        "                d[c(i), n*(i+1) + c(j)] = g_bl\n",
        "\n",
        "            return d\n",
        "\n",
        "        D = torch.cat([maked(j) for j in range(1,n+1)], dim=0)\n",
        "\n",
        "        M = torch.cat((torch.cat((A,B),dim=1), torch.cat((C,D),dim=1)), dim=0)\n",
        "        \n",
        "        self.saved_tiles[self.hash_M(a,b,c,d)] = M\n",
        "        \n",
        "        return torch.inverse(M)\n",
        "    \n",
        "    def circuit_solve(self, coords,  v_wl_in, v_bl_in, v_bl_out, v_wl_out):\n",
        "        \n",
        "        g_wl, g_bl = self.g_wl, self.g_bl\n",
        "        g_s_wl_in, g_s_wl_out = torch.ones(self.tile_rows) * 1, torch.ones(self.tile_rows) * 1e-9\n",
        "        g_s_bl_in, g_s_bl_out = torch.ones(self.tile_rows) * 1e-9, torch.ones(self.tile_rows) * 1\n",
        "        m, n = self.tile_rows, self.tile_cols\n",
        "        \n",
        "        \n",
        "        if self.hash_M(*coords) not in self.saved_tiles.keys():\n",
        "            #print(coords)\n",
        "            M = self.make_M(*coords)\n",
        "        else:\n",
        "            M = self.saved_tiles[self.hash_M(*coords)]\n",
        "        \n",
        "        E = torch.cat([torch.cat(((v_wl_in[i]*g_s_wl_in[i]).view(1), #EW\n",
        "                                  torch.zeros(n-2),\n",
        "                                  (v_wl_out[i]*g_s_wl_out[i]).view(1)))\n",
        "                                 for i in range(m)] +\n",
        "                      [torch.cat(((-v_bl_in[i]*g_s_bl_in[i]).view(1), #EB\n",
        "                                  torch.zeros(m-2),\n",
        "                                  (-v_bl_in[i]*g_s_bl_out[i]).view(1)))\n",
        "                                 for i in range(n)]\n",
        "        ).view(-1, 1)\n",
        "        \n",
        "        V = torch.matmul(M, E)\n",
        "        \n",
        "        V = torch.chunk(torch.solve(E, M)[0], 2)\n",
        "\n",
        "        return torch.sum((V[1] - V[0]).view(m,n)*self.W[coords[0]:coords[1],coords[2]:coords[3]],dim=0)\n",
        "\n",
        "    def register_linear(self, matrix, uvectlist, decode, bias=None):\n",
        "\n",
        "        row, col = self.find_space(matrix.size(0), matrix.size(1))\n",
        "        # Need to add checks for bias size and col size\n",
        "        \n",
        "        # Scale matrix                                    \n",
        "        mat_scale_factor = torch.max(torch.abs(matrix)) / torch.max(self.g_on) * 2\n",
        "        scaled_matrix = matrix / mat_scale_factor\n",
        "        \n",
        "        midpoint = self.conductance_states.size(2) // 2\n",
        "        for i in range(row, row + scaled_matrix.size(0)):\n",
        "            for j in range(col, col + scaled_matrix.size(1)):\n",
        "                \n",
        "                shifted = self.conductance_states[i,j] - self.conductance_states[i,j,midpoint]\n",
        "                idx = torch.min(torch.abs(shifted - scaled_matrix[i-row,j-col]), dim=0)[1]\n",
        "                self.W[i,2*j+1] = self.conductance_states[i,j,idx]\n",
        "                self.W[i,2*j] = self.conductance_states[i,j,midpoint-(idx-midpoint)]\n",
        "        \n",
        "        return ticket(row, col, matrix.size(0), matrix.size(1), matrix, mat_scale_factor, self, uvectlist, decode, self.input_resolution, self.output_resolution)\n",
        "\n",
        "    def which_tiles(self, row, col, m_row, m_col):\n",
        "        return itertools.product(range(row // self.tile_rows, (row + m_row) // self.tile_rows + 1),\n",
        "                                 range(col // self.tile_cols,(col + m_col) // self.tile_cols + 1),\n",
        "        )\n",
        "\n",
        "    def find_space(self, m_row, m_col):\n",
        "        if not self.mapped:\n",
        "            self.mapped.append((0,0,m_row,m_col))\n",
        "        else:\n",
        "            self.mapped.append((self.mapped[-1][0] + self.mapped[-1][2], self.mapped[-1][1] + self.mapped[-1][3], m_row, m_col))\n",
        "        return self.mapped[-1][0], self.mapped[-1][1] \n",
        "    \n",
        "    def clear(self):\n",
        "        self.mapped = []\n",
        "        self.W = torch.ones(self.size) * self.g_on\n",
        "\n",
        "    def conductance_update(self):\n",
        "        self.conductance_states = torch.cat([torch.cat([torch.linspace(self.g_off[i,j], self.g_on[i,j],2**self.resolution - 1).unsqueeze(0)\n",
        "                                                        for j in range(self.size[1])],dim=0).unsqueeze(0)\n",
        "                                             for i in range(self.size[0])],dim=0)"
      ],
      "metadata": {
        "id": "DggdICFfeSG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNetM(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNetM, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        # self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "        self.uvect = [2*(torch.rand(512,1) - 0.5) for i in range(0,10)] # \n",
        "        crb1 = crossbar(device_params)\n",
        "        # Can test using more than 1 crossbar linear layers.\n",
        "        # Easiest implementation is to create a crossbar for each linear layer\n",
        "        self.fc1 = Linear(512, 10,crb1,self.uvect)\n",
        "        self.fc1.use_cb(True)\n",
        "        #self.fc2 = nn.Linear(64*2*2, 10)\n",
        "        self.traincount = 0\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(512, 1)\n",
        "        #print(out.shape)\n",
        "        out = self.fc1(out)\n",
        "        out = out.t()\n",
        "        \n",
        "        out = F.log_softmax(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18M():\n",
        "    return ResNetM(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34M():\n",
        "    return ResNetM(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50M():\n",
        "    return ResNetM(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101M():\n",
        "    return ResNetM(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152M():\n",
        "    return ResNetM(Bottleneck, [3, 8, 36, 3])"
      ],
      "metadata": {
        "id": "BOfprnTgeYY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('model_mnist.pth')\n",
        "temp_model = ResNet18()\n",
        "#Net2.load_state_dict(torch.load(\"model5.pth\"))\n",
        "\n",
        "from collections import OrderedDict\n",
        "new_state_dict = OrderedDict()\n",
        "for k, v in state_dict.items():\n",
        "    name = k[7:] # remove `module.`\n",
        "    new_state_dict[name] = v\n",
        "# load params\n",
        "temp_model.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95duyhurlJFD",
        "outputId": "3e0185ad-408f-48f2-d7c1-648e55d9522a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('model_mnist.pth')\n",
        "model = ResNet18M()\n",
        "# Net2.load_state_dict(torch.load(\"model5.pth\"))\n",
        "\n",
        "from collections import OrderedDict\n",
        "new_state_dict = OrderedDict()\n",
        "for k, v in state_dict.items():\n",
        "    name = k[7:] # remove `module.`\n",
        "    new_state_dict[name] = v\n",
        "# load params\n",
        "model.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "mYWsE0ZHeY5K",
        "outputId": "70f5fa2e-de38-4d4a-9679-2b2f7196df7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-9e968f8793c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnew_state_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# load params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1605\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNetM:\n\tMissing key(s) in state_dict: \"fc1.W\", \"fc1.b\". \n\tUnexpected key(s) in state_dict: \"linear.weight\", \"linear.bias\". "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# crossbar update\n",
        "device_params = {\"Vdd\": 1.8,\n",
        "                 \"r_wl\": 20,\n",
        "                 \"r_bl\": 20,\n",
        "                 \"m\": 600,\n",
        "                 \"n\": 600,\n",
        "                 \"r_on_mean\": 1e4,\n",
        "                 \"r_on_stddev\": 1e3,\n",
        "                 \"r_off_mean\": 1e5,\n",
        "                 \"r_off_stddev\": 1e4,\n",
        "                 \"dac_resolution\": 5,\n",
        "                 \"adc_resolution\": 8.3,\n",
        "                 \"device_resolution\": 6,\n",
        "                 \"bias_scheme\": 1/3,\n",
        "                 \"tile_rows\": 4,\n",
        "                 \"tile_cols\": 4,\n",
        "                 \"r_cmos_line\": 600,\n",
        "                 \"r_cmos_transistor\": 20, \n",
        "                 \"p_stuck_on\": 0.01,\n",
        "                 \"p_stuck_off\": 0.01}\n",
        "crb_new = crossbar(device_params)\n",
        "\n",
        "model.fc1.W = torch.nn.parameter.Parameter(temp_model.linear.weight.data)\n",
        "model.fc1.b = torch.nn.parameter.Parameter(temp_model.linear.bias.data)\n",
        "\n",
        "model.fc1.cb = crb_new\n",
        "model.fc1.remap()"
      ],
      "metadata": {
        "id": "21mrnnbTk5Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkHAff_AmWl6",
        "outputId": "29dec128-0846-4847-e8ac-403e5eee06a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetM(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def network_tester(model, test_loader, test_size, epoch, log = True):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            if batch_idx * len(data) > test_size:\n",
        "                break\n",
        "            output = model(data)\n",
        "\n",
        "            pred = output.data.max(1, keepdim=True)[1][0]\n",
        "            \n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "            total+=target.size(0)\n",
        "\n",
        "            if batch_idx % 1000 == 0 and log:\n",
        "              with open('log_baseline_test.csv', 'a') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([batch_idx + test_size * 100, test_loss/(batch_idx+1), correct.item()/total])\n",
        "              print(\"Epoch\", epoch, 'iteration',batch_idx, 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                          % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    return torch.div(correct, float(total))"
      ],
      "metadata": {
        "id": "37ZKUDaDmZDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../datasets/', train=True, download=True, \n",
        "                               transform=MNISTtransform), \n",
        "                               batch_size=1, shuffle=True)\n",
        "'''Train CIFAR10 with PyTorch.'''\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# import torch.nn.functional as F\n",
        "# import torch.backends.cudnn as cudnn\n",
        "\n",
        "# import torchvision\n",
        "# import torchvision.transforms as transforms\n",
        "\n",
        "# import os\n",
        "# import argparse\n",
        "# import csv\n",
        "\n",
        "# print('==> Preparing data..')\n",
        "# transform_train = transforms.Compose([\n",
        "#     transforms.RandomCrop(32, padding=4),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "# ])\n",
        "\n",
        "# transform_test = transforms.Compose([\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "# ])\n",
        "\n",
        "# trainset = torchvision.datasets.CIFAR10(\n",
        "#     root='./data', train=True, download=True, transform=transform_train)\n",
        "# trainloader = torch.utils.data.DataLoader(\n",
        "#     trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "# testset = torchvision.datasets.CIFAR10(\n",
        "#     root='./data', train=False, download=True, transform=transform_test)\n",
        "# testloader = torch.utils.data.DataLoader(\n",
        "#     testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "# classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "#            'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "network_tester(model, testloader, 9000, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuG8XPrkmwbC",
        "outputId": "605836e3-7a0f-4712-b999-5d4aa97f43e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:113: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iteration 0 Loss: 0.000 | Acc: 100.000% (1/1)\n",
            "Epoch 1 iteration 1000 Loss: 0.000 | Acc: 99.500% (996/1001)\n",
            "Epoch 1 iteration 2000 Loss: 0.000 | Acc: 99.600% (1993/2001)\n",
            "Epoch 1 iteration 3000 Loss: 0.000 | Acc: 99.567% (2988/3001)\n",
            "Epoch 1 iteration 4000 Loss: 0.000 | Acc: 99.625% (3986/4001)\n",
            "Epoch 1 iteration 5000 Loss: 0.000 | Acc: 99.600% (4981/5001)\n",
            "Epoch 1 iteration 6000 Loss: 0.000 | Acc: 99.517% (5972/6001)\n",
            "Epoch 1 iteration 7000 Loss: 0.000 | Acc: 99.486% (6965/7001)\n",
            "Epoch 1 iteration 8000 Loss: 0.000 | Acc: 99.525% (7963/8001)\n",
            "Epoch 1 iteration 9000 Loss: 0.000 | Acc: 99.522% (8958/9001)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9952)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet-18 and MNIST"
      ],
      "metadata": {
        "id": "zNppg3UnxmWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "MNISTtransform = transforms.Compose([\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../datasets/', train=False, download=True, \n",
        "                               transform=MNISTtransform), \n",
        "                               batch_size=32, shuffle=True)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../datasets/', train=True, download=True, \n",
        "                               transform=MNISTtransform), \n",
        "                               batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "52393d806ccf41a1a7ad5d5bbea7575f",
            "c000e8a47638441bb483f05376afc646",
            "14f47adbba7e43de84eeb333f7c1db1f",
            "1992fa31a8a14e1ea0b70d5d810fd3ea",
            "0550db54580e4f68b0e3636efe2ed15f",
            "8421853411ab4e0d8cfc5a3ff7f6c937",
            "231e7ae79e5d4f56a2caa3ab1efc4ef5",
            "5f39c1cc1db84ea3adba42b4419b5984",
            "82092e58fc1342eea52c31ae50efe824",
            "14afd8cfc9f84ac48ce798a5e6db77d7",
            "5a23bc0274dc41029f49a47a3e5c242b",
            "47babf5622054c24acb5928f81c164df",
            "15916ee5eda14c43ad13420fc1534546",
            "465f77d1661f4d1d9afa362446ac729d",
            "dcecac3b663044f5a976ed1ae5ca43c1",
            "0f8d5638f445429aaee18807ba98a484",
            "e45307963fc34e2ea1d68d963dfcc315",
            "acaadb9bda7a434e8a1249648fa947ca",
            "f0970eeb34a34250b2e4ce173907b756",
            "87959a4157ba47abbbc6fb959331bbc6",
            "2888d31c847244faa121bda6d8d7e113",
            "d026d35c16434dff866a74b38f1e004c",
            "e6e039cfed914815b3d395a44711fb2a",
            "4200c41986384e559b7f5f188d6621f6",
            "c7d207facc904eacba2fcd3fab0f6607",
            "0564eb8fd19f42bb94bfad8e4b09d02b",
            "a94aea0377fc45f8a8d1325a0ea205d0",
            "d94a2c8f371e45d5b56a09e0f8f0f95a",
            "258a88bb0892472fa4b75bd5d0e916e4",
            "b3af06b6e2b24ce893576ae11b91715c",
            "4c08c35afff147f58ec2a816d101d80e",
            "06daa50b278f4498b20335d86b0ad90f",
            "260bcb47b9f249258cae79807674d1af",
            "786130b1d6c34921b23b59823a9f3b63",
            "b14ef69981ec41c689a671a3447b1921",
            "cf045f6d5fec484d9a74d29ef1bf930e",
            "e0c1f923c76c471c884aed62b330b77f",
            "f2910f4db7c44feaa40e65fb3b749ebd",
            "a3d985aa530545a78f805275a9b2437d",
            "0835e33a007145d9aebd2e6981e7563e",
            "996bdb8da15045508cc9125ebbcc2206",
            "1bb1b23805704c04bf0625e1b6e3a796",
            "2655fc4673f347e197b1788d1f6cd4e8",
            "bef089190b044195ad9615b4890eb9aa"
          ]
        },
        "id": "90YZWch4xxjr",
        "outputId": "977e9005-5d26-4aa3-92c4-12d56483c00e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52393d806ccf41a1a7ad5d5bbea7575f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../datasets/MNIST/raw/train-images-idx3-ubyte.gz to ../datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47babf5622054c24acb5928f81c164df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ../datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6e039cfed914815b3d395a44711fb2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ../datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "786130b1d6c34921b23b59823a9f3b63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../datasets/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])"
      ],
      "metadata": {
        "id": "mnJ3ofDzycq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Train CIFAR10 with PyTorch.'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import csv\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Model\n",
        "print('==> Building model..')\n",
        "# net = VGG('VGG19')\n",
        "net = ResNet18()\n",
        "\n",
        "net = net.to(device)\n",
        "if device == 'cuda':\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        if batch_idx % 50 == 0:\n",
        "          with open('log_baseline_train.csv', 'a') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([batch_idx + epoch * 400, train_loss/(batch_idx+1), correct/total])\n",
        "          print(\"Epoch\", epoch, 'iteration',batch_idx, 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                        % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "              with open('log_baseline_test.csv', 'a') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([batch_idx + epoch * 100, test_loss/(batch_idx+1), correct/total])\n",
        "              print(\"Epoch\", epoch, 'iteration',batch_idx, 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                          % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, './checkpoint/ckpt.pth')\n",
        "        best_acc = acc\n",
        "\n",
        "with open('log_baseline_train.csv', 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"iteration\", \"train_loss\", \"train_acc\"])\n",
        "\n",
        "with open('log_baseline_test.csv', 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"iteration\", \"test_loss\", \"test_acc\"])\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch+20):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zHdl8YPtyKo-",
        "outputId": "81f39dcf-7bc5-4e7a-97fb-ed9919701931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Building model..\n",
            "\n",
            "Epoch: 0\n",
            "Epoch 0 iteration 0 Loss: 2.453 | Acc: 9.375% (3/32)\n",
            "Epoch 0 iteration 50 Loss: 1.778 | Acc: 43.934% (717/1632)\n",
            "Epoch 0 iteration 100 Loss: 1.239 | Acc: 63.026% (2037/3232)\n",
            "Epoch 0 iteration 150 Loss: 0.935 | Acc: 72.661% (3511/4832)\n",
            "Epoch 0 iteration 200 Loss: 0.752 | Acc: 78.125% (5025/6432)\n",
            "Epoch 0 iteration 250 Loss: 0.635 | Acc: 81.686% (6561/8032)\n",
            "Epoch 0 iteration 300 Loss: 0.551 | Acc: 84.178% (8108/9632)\n",
            "Epoch 0 iteration 350 Loss: 0.489 | Acc: 85.986% (9658/11232)\n",
            "Epoch 0 iteration 400 Loss: 0.439 | Acc: 87.430% (11219/12832)\n",
            "Epoch 0 iteration 450 Loss: 0.402 | Acc: 88.463% (12767/14432)\n",
            "Epoch 0 iteration 500 Loss: 0.373 | Acc: 89.259% (14310/16032)\n",
            "Epoch 0 iteration 550 Loss: 0.348 | Acc: 90.012% (15871/17632)\n",
            "Epoch 0 iteration 600 Loss: 0.326 | Acc: 90.661% (17436/19232)\n",
            "Epoch 0 iteration 650 Loss: 0.306 | Acc: 91.201% (18999/20832)\n",
            "Epoch 0 iteration 700 Loss: 0.289 | Acc: 91.735% (20578/22432)\n",
            "Epoch 0 iteration 750 Loss: 0.275 | Acc: 92.148% (22145/24032)\n",
            "Epoch 0 iteration 800 Loss: 0.262 | Acc: 92.525% (23716/25632)\n",
            "Epoch 0 iteration 850 Loss: 0.252 | Acc: 92.810% (25274/27232)\n",
            "Epoch 0 iteration 900 Loss: 0.242 | Acc: 93.115% (26847/28832)\n",
            "Epoch 0 iteration 950 Loss: 0.233 | Acc: 93.372% (28415/30432)\n",
            "Epoch 0 iteration 1000 Loss: 0.225 | Acc: 93.622% (29989/32032)\n",
            "Epoch 0 iteration 1050 Loss: 0.217 | Acc: 93.845% (31562/33632)\n",
            "Epoch 0 iteration 1100 Loss: 0.210 | Acc: 94.017% (33124/35232)\n",
            "Epoch 0 iteration 1150 Loss: 0.203 | Acc: 94.222% (34704/36832)\n",
            "Epoch 0 iteration 1200 Loss: 0.197 | Acc: 94.385% (36274/38432)\n",
            "Epoch 0 iteration 1250 Loss: 0.191 | Acc: 94.542% (37847/40032)\n",
            "Epoch 0 iteration 1300 Loss: 0.186 | Acc: 94.701% (39426/41632)\n",
            "Epoch 0 iteration 1350 Loss: 0.181 | Acc: 94.846% (41004/43232)\n",
            "Epoch 0 iteration 1400 Loss: 0.175 | Acc: 95.004% (42592/44832)\n",
            "Epoch 0 iteration 1450 Loss: 0.171 | Acc: 95.133% (44172/46432)\n",
            "Epoch 0 iteration 1500 Loss: 0.167 | Acc: 95.255% (45753/48032)\n",
            "Epoch 0 iteration 1550 Loss: 0.163 | Acc: 95.364% (47331/49632)\n",
            "Epoch 0 iteration 1600 Loss: 0.160 | Acc: 95.444% (48898/51232)\n",
            "Epoch 0 iteration 1650 Loss: 0.157 | Acc: 95.531% (50471/52832)\n",
            "Epoch 0 iteration 1700 Loss: 0.154 | Acc: 95.615% (52045/54432)\n",
            "Epoch 0 iteration 1750 Loss: 0.151 | Acc: 95.701% (53623/56032)\n",
            "Epoch 0 iteration 1800 Loss: 0.148 | Acc: 95.763% (55190/57632)\n",
            "Epoch 0 iteration 1850 Loss: 0.145 | Acc: 95.840% (56768/59232)\n",
            "Epoch 0 iteration 0 Loss: 0.027 | Acc: 100.000% (32/32)\n",
            "Epoch 0 iteration 100 Loss: 0.056 | Acc: 98.144% (3172/3232)\n",
            "Epoch 0 iteration 200 Loss: 0.050 | Acc: 98.399% (6329/6432)\n",
            "Epoch 0 iteration 300 Loss: 0.050 | Acc: 98.463% (9484/9632)\n",
            "Saving..\n",
            "\n",
            "Epoch: 1\n",
            "Epoch 1 iteration 0 Loss: 0.003 | Acc: 100.000% (32/32)\n",
            "Epoch 1 iteration 50 Loss: 0.036 | Acc: 98.897% (1614/1632)\n",
            "Epoch 1 iteration 100 Loss: 0.030 | Acc: 99.072% (3202/3232)\n",
            "Epoch 1 iteration 150 Loss: 0.030 | Acc: 99.007% (4784/4832)\n",
            "Epoch 1 iteration 200 Loss: 0.029 | Acc: 99.129% (6376/6432)\n",
            "Epoch 1 iteration 250 Loss: 0.029 | Acc: 99.104% (7960/8032)\n",
            "Epoch 1 iteration 300 Loss: 0.029 | Acc: 99.159% (9551/9632)\n",
            "Epoch 1 iteration 350 Loss: 0.027 | Acc: 99.234% (11146/11232)\n",
            "Epoch 1 iteration 400 Loss: 0.026 | Acc: 99.283% (12740/12832)\n",
            "Epoch 1 iteration 450 Loss: 0.027 | Acc: 99.272% (14327/14432)\n",
            "Epoch 1 iteration 500 Loss: 0.028 | Acc: 99.233% (15909/16032)\n",
            "Epoch 1 iteration 550 Loss: 0.028 | Acc: 99.212% (17493/17632)\n",
            "Epoch 1 iteration 600 Loss: 0.029 | Acc: 99.199% (19078/19232)\n",
            "Epoch 1 iteration 650 Loss: 0.029 | Acc: 99.160% (20657/20832)\n",
            "Epoch 1 iteration 700 Loss: 0.029 | Acc: 99.162% (22244/22432)\n",
            "Epoch 1 iteration 750 Loss: 0.029 | Acc: 99.143% (23826/24032)\n",
            "Epoch 1 iteration 800 Loss: 0.029 | Acc: 99.146% (25413/25632)\n",
            "Epoch 1 iteration 850 Loss: 0.029 | Acc: 99.159% (27003/27232)\n",
            "Epoch 1 iteration 900 Loss: 0.029 | Acc: 99.164% (28591/28832)\n",
            "Epoch 1 iteration 950 Loss: 0.028 | Acc: 99.172% (30180/30432)\n",
            "Epoch 1 iteration 1000 Loss: 0.029 | Acc: 99.148% (31759/32032)\n",
            "Epoch 1 iteration 1050 Loss: 0.030 | Acc: 99.138% (33342/33632)\n",
            "Epoch 1 iteration 1100 Loss: 0.030 | Acc: 99.143% (34930/35232)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-fbcb866fb5b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-fbcb866fb5b1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-b69b6630babd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-b69b6630babd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2439\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2440\u001b[0m     )\n\u001b[1;32m   2441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), \"model_mnist.pth\")"
      ],
      "metadata": {
        "id": "ZzIK4Dety9K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN and Sentimental Analysis"
      ],
      "metadata": {
        "id": "OTxLDYuhVRxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# file location (make sure to use your file location)\n",
        "file_dir = '/content/'\n",
        "\n",
        "# load csv file\n",
        "def get_data():\n",
        "    return csv.reader(open(file_dir + \"training.1600000.processed.noemoticon.csv\",\"rt\", encoding=\"latin-1\"))\n",
        "\n",
        "# print only the first tweet\n",
        "for i, line in enumerate(get_data()):\n",
        "    if line[0] != '0':\n",
        "        print(line[0], line[-1])\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmaetGvDVUU_",
        "outputId": "2d0f0558-2238-4195-cbd8-e5260f729a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 I LOVE @Health4UandPets u guys r the best!! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)\n",
        "\n",
        "def split_tweet(tweet):\n",
        "    # separate punctuations\n",
        "    tweet = tweet.replace(\".\", \" . \") \\\n",
        "                 .replace(\",\", \" , \") \\\n",
        "                 .replace(\";\", \" ; \") \\\n",
        "                 .replace(\"?\", \" ? \")\n",
        "    return tweet.lower().split()\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50, max_vectors=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtepdWHBXmKM",
        "outputId": "fccff41e-036b-44a4-f12e-e8f6cd54b86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:42, 5.31MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:09<00:00, 43070.83it/s]\n",
            "100%|█████████▉| 9999/10000 [00:00<00:00, 40258.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def get_tweet_vectors(glove_vector):\n",
        "    train, valid, test = [], [], []\n",
        "    for i, line in enumerate(get_data()):\n",
        "        tweet = line[-1]\n",
        "        if i % 59 == 0:\n",
        "            # obtain an embedding for the entire tweet\n",
        "            tweet_emb = sum(glove_vector[w] for w in split_tweet(tweet))\n",
        "            # generate a label: 1 = happy, 0 = sad\n",
        "            label = torch.tensor(int(line[0] == \"4\")).long()\n",
        "            # place the data set in either the training, validation, or test set\n",
        "            if i % 5 < 3:\n",
        "                train.append((tweet_emb, label)) # 60% training\n",
        "            elif i % 5 == 4:\n",
        "                valid.append((tweet_emb, label)) # 20% validation\n",
        "            else:\n",
        "                test.append((tweet_emb, label)) # 20% test\n",
        "    return train, valid, test"
      ],
      "metadata": {
        "id": "ZSq0ipxCXoNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)\n",
        "\n",
        "train, valid, test = get_tweet_vectors(glove)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "deyqhOMHXrLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tweet_words(glove_vector):\n",
        "    train, valid, test = [], [], []\n",
        "    for i, line in enumerate(get_data()):\n",
        "        if i % 29 == 0:\n",
        "            tweet = line[-1]\n",
        "            idxs = [glove_vector.stoi[w]        # lookup the index of word\n",
        "                    for w in split_tweet(tweet)\n",
        "                    if w in glove_vector.stoi] # keep words that has an embedding\n",
        "            if not idxs: # ignore tweets without any word with an embedding\n",
        "                continue\n",
        "            idxs = torch.tensor(idxs) # convert list to pytorch tensor\n",
        "            label = torch.tensor(int(line[0] == \"4\")).long()\n",
        "            if i % 5 < 3:\n",
        "                train.append((idxs, label))\n",
        "            elif i % 5 == 4:\n",
        "                valid.append((idxs, label))\n",
        "            else:\n",
        "                test.append((idxs, label))\n",
        "    return train, valid, test\n",
        "\n",
        "train, valid, test = get_tweet_words(glove)"
      ],
      "metadata": {
        "id": "Uup3TdZ3Xtqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_rnn_network(model, train, valid, num_epochs=5, learning_rate=1e-5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9)\n",
        "    losses, train_acc, valid_acc = [], [], []\n",
        "    epochs = []\n",
        "    for epoch in range(num_epochs):\n",
        "        i = 0\n",
        "        for tweets, labels in train:\n",
        "            i += 1\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(tweets)\n",
        "            loss = criterion(pred, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if i % 100 == 1:\n",
        "                train_acc.append(get_accuracy(model, train_loader))\n",
        "                valid_acc.append(get_accuracy(model, valid_loader))\n",
        "                print(\"Epoch %d; Iteration %d; Loss %f; Train Acc %f; Val Acc %f\" % (\n",
        "                      epoch+1, i, loss, train_acc[-1], valid_acc[-1]))\n",
        "                with open('log_baseline_test2.csv', 'a') as f:\n",
        "                    writer = csv.writer(f)\n",
        "                    writer.writerow([epoch * 100 + i, loss, valid_acc[-1]])\n",
        "                  \n",
        "        losses.append(float(loss))\n",
        "\n",
        "        epochs.append(epoch)\n",
        "        train_acc.append(get_accuracy(model, train_loader))\n",
        "        valid_acc.append(get_accuracy(model, valid_loader))\n",
        "        print(\"End of Epoch %d; Loss %f; Train Acc %f; Val Acc %f\" % (\n",
        "              epoch+1, loss, train_acc[-1], valid_acc[-1]))\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    correct, total = 0, 0\n",
        "    for tweets, labels in data_loader:\n",
        "        output = model(tweets)\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += labels.shape[0]\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "Ny5XBB60XvUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TweetRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(TweetRNN, self).__init__()\n",
        "        self.emb = nn.Embedding.from_pretrained(glove.vectors)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Look up the embedding\n",
        "        x = self.emb(x)\n",
        "        # Set an initial hidden state\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        # Forward propagate the RNN\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        # Pass the output of the last time step to the classifier\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "model = TweetRNN(50, 50, 2)"
      ],
      "metadata": {
        "id": "bcPwEbzTXyRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "tweet_padded = pad_sequence([tweet for tweet, label in train[:10]],\n",
        "                            batch_first=True)"
      ],
      "metadata": {
        "id": "5HJ2yIIwX0EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class TweetBatcher:\n",
        "    def __init__(self, tweets, batch_size=32, drop_last=False):\n",
        "        # store tweets by length\n",
        "        self.tweets_by_length = {}\n",
        "        for words, label in tweets:\n",
        "            # compute the length of the tweet\n",
        "            wlen = words.shape[0]\n",
        "            # put the tweet in the correct key inside self.tweet_by_length\n",
        "            if wlen not in self.tweets_by_length:\n",
        "                self.tweets_by_length[wlen] = []\n",
        "            self.tweets_by_length[wlen].append((words, label),)\n",
        "         \n",
        "        #  create a DataLoader for each set of tweets of the same length\n",
        "        self.loaders = {wlen : torch.utils.data.DataLoader(\n",
        "                                    tweets,\n",
        "                                    batch_size=batch_size,\n",
        "                                    shuffle=True,\n",
        "                                    drop_last=drop_last) # omit last batch if smaller than batch_size\n",
        "            for wlen, tweets in self.tweets_by_length.items()}\n",
        "        \n",
        "    def __iter__(self): # called by Python to create an iterator\n",
        "        # make an iterator for every tweet length\n",
        "        iters = [iter(loader) for loader in self.loaders.values()]\n",
        "        while iters:\n",
        "            # pick an iterator (a length)\n",
        "            im = random.choice(iters)\n",
        "            try:\n",
        "                yield next(im)\n",
        "            except StopIteration:\n",
        "                # no more elements in the iterator, remove it\n",
        "                iters.remove(im)"
      ],
      "metadata": {
        "id": "r4WTFKisX0nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, data_loader):\n",
        "    correct, total = 0, 0\n",
        "    for tweets, labels in data_loader:\n",
        "        output = model(tweets)\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += labels.shape[0]\n",
        "    return correct / total\n",
        "\n",
        "test_loader = TweetBatcher(test, batch_size=64, drop_last=False)\n",
        "get_accuracy(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2on4X0WpX2gl",
        "outputId": "382c75b8-b803-4986-f0d6-0e65dbd80be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4944403937294933"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = TweetRNN(50, 100, 2)\n",
        "train_loader = TweetBatcher(train, batch_size=64, drop_last=True)\n",
        "valid_loader = TweetBatcher(valid, batch_size=64, drop_last=False)\n",
        "train_rnn_network(net, train_loader, valid_loader, num_epochs=40, learning_rate=5e-3)\n",
        "get_accuracy(net, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFvQixhlX4rw",
        "outputId": "73c513c7-b29b-4e4f-ae3e-5e0c46a0eba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1; Iteration 1; Loss 0.702942; Train Acc 0.508663; Val Acc 0.509484\n",
            "Epoch 1; Iteration 101; Loss 0.688663; Train Acc 0.590064; Val Acc 0.594930\n",
            "Epoch 1; Iteration 201; Loss 0.644955; Train Acc 0.621755; Val Acc 0.620190\n",
            "Epoch 1; Iteration 301; Loss 0.677277; Train Acc 0.635364; Val Acc 0.640890\n",
            "Epoch 1; Iteration 401; Loss 0.643282; Train Acc 0.621661; Val Acc 0.625935\n",
            "End of Epoch 1; Loss 0.619829; Train Acc 0.664409; Val Acc 0.669433\n",
            "Epoch 2; Iteration 1; Loss 0.691065; Train Acc 0.661983; Val Acc 0.658672\n",
            "Epoch 2; Iteration 101; Loss 0.629911; Train Acc 0.669512; Val Acc 0.672898\n",
            "Epoch 2; Iteration 201; Loss 0.626382; Train Acc 0.560736; Val Acc 0.564290\n",
            "Epoch 2; Iteration 301; Loss 0.670268; Train Acc 0.646705; Val Acc 0.651924\n",
            "Epoch 2; Iteration 401; Loss 0.583889; Train Acc 0.673513; Val Acc 0.673263\n",
            "End of Epoch 2; Loss 0.620507; Train Acc 0.666677; Val Acc 0.665603\n",
            "Epoch 3; Iteration 1; Loss 0.593867; Train Acc 0.658424; Val Acc 0.656666\n",
            "Epoch 3; Iteration 101; Loss 0.558028; Train Acc 0.673671; Val Acc 0.672898\n",
            "Epoch 3; Iteration 201; Loss 0.647654; Train Acc 0.667685; Val Acc 0.666879\n",
            "Epoch 3; Iteration 301; Loss 0.644139; Train Acc 0.668819; Val Acc 0.673992\n",
            "Epoch 3; Iteration 401; Loss 0.583390; Train Acc 0.658392; Val Acc 0.659311\n",
            "End of Epoch 3; Loss 0.591407; Train Acc 0.677262; Val Acc 0.678005\n",
            "Epoch 4; Iteration 1; Loss 0.645435; Train Acc 0.668693; Val Acc 0.674357\n",
            "Epoch 4; Iteration 101; Loss 0.562949; Train Acc 0.676096; Val Acc 0.675816\n",
            "Epoch 4; Iteration 201; Loss 0.620820; Train Acc 0.679782; Val Acc 0.679373\n",
            "Epoch 4; Iteration 301; Loss 0.595314; Train Acc 0.666677; Val Acc 0.660496\n",
            "Epoch 4; Iteration 401; Loss 0.673570; Train Acc 0.667024; Val Acc 0.666241\n",
            "End of Epoch 4; Loss 0.653999; Train Acc 0.673765; Val Acc 0.673810\n",
            "Epoch 5; Iteration 1; Loss 0.502700; Train Acc 0.672789; Val Acc 0.671439\n",
            "Epoch 5; Iteration 101; Loss 0.646918; Train Acc 0.679656; Val Acc 0.678734\n",
            "Epoch 5; Iteration 201; Loss 0.662947; Train Acc 0.673513; Val Acc 0.670254\n",
            "Epoch 5; Iteration 301; Loss 0.624369; Train Acc 0.652029; Val Acc 0.654204\n",
            "Epoch 5; Iteration 401; Loss 0.560654; Train Acc 0.680223; Val Acc 0.677731\n",
            "End of Epoch 5; Loss 0.608622; Train Acc 0.677419; Val Acc 0.676363\n",
            "Epoch 6; Iteration 1; Loss 0.689335; Train Acc 0.676506; Val Acc 0.676090\n",
            "Epoch 6; Iteration 101; Loss 0.590154; Train Acc 0.680979; Val Acc 0.677458\n",
            "Epoch 6; Iteration 201; Loss 0.543223; Train Acc 0.682838; Val Acc 0.682747\n",
            "Epoch 6; Iteration 301; Loss 0.586302; Train Acc 0.679309; Val Acc 0.677640\n",
            "Epoch 6; Iteration 401; Loss 0.649912; Train Acc 0.675529; Val Acc 0.673354\n",
            "End of Epoch 6; Loss 0.594186; Train Acc 0.682617; Val Acc 0.683111\n",
            "Epoch 7; Iteration 1; Loss 0.572848; Train Acc 0.684003; Val Acc 0.685847\n",
            "Epoch 7; Iteration 101; Loss 0.590093; Train Acc 0.682428; Val Acc 0.680649\n",
            "Epoch 7; Iteration 201; Loss 0.586842; Train Acc 0.683562; Val Acc 0.685026\n",
            "Epoch 7; Iteration 301; Loss 0.676723; Train Acc 0.676695; Val Acc 0.677458\n",
            "Epoch 7; Iteration 401; Loss 0.607312; Train Acc 0.680381; Val Acc 0.681288\n",
            "End of Epoch 7; Loss 0.608090; Train Acc 0.685956; Val Acc 0.683385\n",
            "Epoch 8; Iteration 1; Loss 0.608867; Train Acc 0.685610; Val Acc 0.684206\n",
            "Epoch 8; Iteration 101; Loss 0.593625; Train Acc 0.668882; Val Acc 0.669980\n",
            "Epoch 8; Iteration 201; Loss 0.584942; Train Acc 0.651084; Val Acc 0.651195\n",
            "Epoch 8; Iteration 301; Loss 0.659591; Train Acc 0.685736; Val Acc 0.683476\n",
            "Epoch 8; Iteration 401; Loss 0.500732; Train Acc 0.686334; Val Acc 0.684479\n",
            "End of Epoch 8; Loss 0.602216; Train Acc 0.688256; Val Acc 0.684479\n",
            "Epoch 9; Iteration 1; Loss 0.528736; Train Acc 0.687721; Val Acc 0.684206\n",
            "Epoch 9; Iteration 101; Loss 0.607775; Train Acc 0.686303; Val Acc 0.683294\n",
            "Epoch 9; Iteration 201; Loss 0.608432; Train Acc 0.685326; Val Acc 0.686668\n",
            "Epoch 9; Iteration 301; Loss 0.563214; Train Acc 0.683909; Val Acc 0.679555\n",
            "Epoch 9; Iteration 401; Loss 0.649156; Train Acc 0.660692; Val Acc 0.653018\n",
            "End of Epoch 9; Loss 0.602493; Train Acc 0.688225; Val Acc 0.685756\n",
            "Epoch 10; Iteration 1; Loss 0.634592; Train Acc 0.688130; Val Acc 0.685847\n",
            "Epoch 10; Iteration 101; Loss 0.695578; Train Acc 0.690871; Val Acc 0.686394\n",
            "Epoch 10; Iteration 201; Loss 0.599497; Train Acc 0.659495; Val Acc 0.653566\n",
            "Epoch 10; Iteration 301; Loss 0.584993; Train Acc 0.688760; Val Acc 0.680467\n",
            "Epoch 10; Iteration 401; Loss 0.521420; Train Acc 0.656282; Val Acc 0.656940\n",
            "End of Epoch 10; Loss 0.619964; Train Acc 0.685358; Val Acc 0.685756\n",
            "Epoch 11; Iteration 1; Loss 0.566156; Train Acc 0.683972; Val Acc 0.681652\n",
            "Epoch 11; Iteration 101; Loss 0.498310; Train Acc 0.692005; Val Acc 0.689586\n",
            "Epoch 11; Iteration 201; Loss 0.761928; Train Acc 0.678711; Val Acc 0.669889\n",
            "Epoch 11; Iteration 301; Loss 0.706876; Train Acc 0.680412; Val Acc 0.678643\n",
            "Epoch 11; Iteration 401; Loss 0.613251; Train Acc 0.687342; Val Acc 0.683567\n",
            "End of Epoch 11; Loss 0.701476; Train Acc 0.692887; Val Acc 0.689404\n",
            "Epoch 12; Iteration 1; Loss 0.618594; Train Acc 0.694966; Val Acc 0.690680\n",
            "Epoch 12; Iteration 101; Loss 0.535668; Train Acc 0.685799; Val Acc 0.678734\n",
            "Epoch 12; Iteration 201; Loss 0.437055; Train Acc 0.686334; Val Acc 0.683841\n",
            "Epoch 12; Iteration 301; Loss 0.597437; Train Acc 0.693233; Val Acc 0.685938\n",
            "Epoch 12; Iteration 401; Loss 0.532122; Train Acc 0.674301; Val Acc 0.663688\n",
            "End of Epoch 12; Loss 0.654048; Train Acc 0.663968; Val Acc 0.660223\n",
            "Epoch 13; Iteration 1; Loss 0.586592; Train Acc 0.668221; Val Acc 0.664053\n",
            "Epoch 13; Iteration 101; Loss 0.603599; Train Acc 0.694966; Val Acc 0.688583\n",
            "Epoch 13; Iteration 201; Loss 0.708045; Train Acc 0.684066; Val Acc 0.672169\n",
            "Epoch 13; Iteration 301; Loss 0.579510; Train Acc 0.694745; Val Acc 0.681379\n",
            "Epoch 13; Iteration 401; Loss 0.532701; Train Acc 0.695218; Val Acc 0.683841\n",
            "End of Epoch 13; Loss 0.620822; Train Acc 0.698211; Val Acc 0.692048\n",
            "Epoch 14; Iteration 1; Loss 0.573442; Train Acc 0.697549; Val Acc 0.692869\n",
            "Epoch 14; Iteration 101; Loss 0.459298; Train Acc 0.697770; Val Acc 0.689677\n",
            "Epoch 14; Iteration 201; Loss 0.676512; Train Acc 0.682743; Val Acc 0.671621\n",
            "Epoch 14; Iteration 301; Loss 0.565987; Train Acc 0.699660; Val Acc 0.690680\n",
            "Epoch 14; Iteration 401; Loss 0.580885; Train Acc 0.681609; Val Acc 0.670071\n",
            "End of Epoch 14; Loss 0.572386; Train Acc 0.687311; Val Acc 0.683476\n",
            "Epoch 15; Iteration 1; Loss 0.610357; Train Acc 0.694651; Val Acc 0.689130\n",
            "Epoch 15; Iteration 101; Loss 0.583961; Train Acc 0.700195; Val Acc 0.690224\n",
            "Epoch 15; Iteration 201; Loss 0.544440; Train Acc 0.684917; Val Acc 0.681561\n",
            "Epoch 15; Iteration 301; Loss 0.601818; Train Acc 0.694934; Val Acc 0.680649\n",
            "Epoch 15; Iteration 401; Loss 0.540881; Train Acc 0.701140; Val Acc 0.689860\n",
            "End of Epoch 15; Loss 0.560605; Train Acc 0.690713; Val Acc 0.686941\n",
            "Epoch 16; Iteration 1; Loss 0.512984; Train Acc 0.690052; Val Acc 0.684570\n",
            "Epoch 16; Iteration 101; Loss 0.551738; Train Acc 0.685106; Val Acc 0.677184\n",
            "Epoch 16; Iteration 201; Loss 0.549896; Train Acc 0.700794; Val Acc 0.691501\n",
            "Epoch 16; Iteration 301; Loss 0.630201; Train Acc 0.699471; Val Acc 0.689039\n",
            "Epoch 16; Iteration 401; Loss 0.660542; Train Acc 0.700195; Val Acc 0.686577\n",
            "End of Epoch 16; Loss 0.522934; Train Acc 0.705330; Val Acc 0.695149\n",
            "Epoch 17; Iteration 1; Loss 0.549085; Train Acc 0.702306; Val Acc 0.691775\n",
            "Epoch 17; Iteration 101; Loss 0.559825; Train Acc 0.707882; Val Acc 0.692231\n",
            "Epoch 17; Iteration 201; Loss 0.510706; Train Acc 0.677923; Val Acc 0.672351\n",
            "Epoch 17; Iteration 301; Loss 0.598495; Train Acc 0.697014; Val Acc 0.678552\n",
            "Epoch 17; Iteration 401; Loss 0.670620; Train Acc 0.705393; Val Acc 0.696972\n",
            "End of Epoch 17; Loss 0.583950; Train Acc 0.691343; Val Acc 0.686759\n",
            "Epoch 18; Iteration 1; Loss 0.613545; Train Acc 0.687185; Val Acc 0.682838\n",
            "Epoch 18; Iteration 101; Loss 0.505019; Train Acc 0.703314; Val Acc 0.693872\n",
            "Epoch 18; Iteration 201; Loss 0.543435; Train Acc 0.703692; Val Acc 0.693781\n",
            "Epoch 18; Iteration 301; Loss 0.640075; Train Acc 0.707693; Val Acc 0.694693\n",
            "Epoch 18; Iteration 401; Loss 0.617371; Train Acc 0.693454; Val Acc 0.677458\n",
            "End of Epoch 18; Loss 0.471073; Train Acc 0.691595; Val Acc 0.678370\n",
            "Epoch 19; Iteration 1; Loss 0.623114; Train Acc 0.693800; Val Acc 0.680011\n",
            "Epoch 19; Iteration 101; Loss 0.597210; Train Acc 0.702715; Val Acc 0.693051\n",
            "Epoch 19; Iteration 201; Loss 0.593697; Train Acc 0.707409; Val Acc 0.697976\n",
            "Epoch 19; Iteration 301; Loss 0.597657; Train Acc 0.710465; Val Acc 0.698340\n",
            "Epoch 19; Iteration 401; Loss 0.561795; Train Acc 0.711127; Val Acc 0.698796\n",
            "End of Epoch 19; Loss 0.591634; Train Acc 0.707126; Val Acc 0.687397\n",
            "Epoch 20; Iteration 1; Loss 0.515687; Train Acc 0.710717; Val Acc 0.695057\n",
            "Epoch 20; Iteration 101; Loss 0.537569; Train Acc 0.711410; Val Acc 0.697611\n",
            "Epoch 20; Iteration 201; Loss 0.617366; Train Acc 0.689579; Val Acc 0.685574\n",
            "Epoch 20; Iteration 301; Loss 0.598889; Train Acc 0.711158; Val Acc 0.693690\n",
            "Epoch 20; Iteration 401; Loss 0.659946; Train Acc 0.713930; Val Acc 0.699343\n",
            "End of Epoch 20; Loss 0.551672; Train Acc 0.714056; Val Acc 0.700985\n",
            "Epoch 21; Iteration 1; Loss 0.605664; Train Acc 0.712292; Val Acc 0.696790\n",
            "Epoch 21; Iteration 101; Loss 0.558270; Train Acc 0.704165; Val Acc 0.685665\n",
            "Epoch 21; Iteration 201; Loss 0.542259; Train Acc 0.677419; Val Acc 0.669159\n",
            "Epoch 21; Iteration 301; Loss 0.535337; Train Acc 0.710591; Val Acc 0.694601\n",
            "Epoch 21; Iteration 401; Loss 0.575760; Train Acc 0.712702; Val Acc 0.694328\n",
            "End of Epoch 21; Loss 0.542617; Train Acc 0.698526; Val Acc 0.688492\n",
            "Epoch 22; Iteration 1; Loss 0.518414; Train Acc 0.703093; Val Acc 0.690407\n",
            "Epoch 22; Iteration 101; Loss 0.583131; Train Acc 0.698526; Val Acc 0.686668\n",
            "Epoch 22; Iteration 201; Loss 0.589976; Train Acc 0.715033; Val Acc 0.699161\n",
            "Epoch 22; Iteration 301; Loss 0.668835; Train Acc 0.681483; Val Acc 0.671621\n",
            "Epoch 22; Iteration 401; Loss 0.479934; Train Acc 0.686712; Val Acc 0.677822\n",
            "End of Epoch 22; Loss 0.430303; Train Acc 0.711914; Val Acc 0.692413\n",
            "Epoch 23; Iteration 1; Loss 0.539478; Train Acc 0.715978; Val Acc 0.698796\n",
            "Epoch 23; Iteration 101; Loss 0.621333; Train Acc 0.717836; Val Acc 0.696334\n",
            "Epoch 23; Iteration 201; Loss 0.610520; Train Acc 0.714277; Val Acc 0.699799\n",
            "Epoch 23; Iteration 301; Loss 0.594301; Train Acc 0.718624; Val Acc 0.701350\n",
            "Epoch 23; Iteration 401; Loss 0.591340; Train Acc 0.714056; Val Acc 0.694237\n",
            "End of Epoch 23; Loss 0.553781; Train Acc 0.706181; Val Acc 0.688309\n",
            "Epoch 24; Iteration 1; Loss 0.666640; Train Acc 0.704039; Val Acc 0.683932\n",
            "Epoch 24; Iteration 101; Loss 0.488504; Train Acc 0.721081; Val Acc 0.702535\n",
            "Epoch 24; Iteration 201; Loss 0.549793; Train Acc 0.720483; Val Acc 0.701532\n",
            "Epoch 24; Iteration 301; Loss 0.618106; Train Acc 0.716639; Val Acc 0.701988\n",
            "Epoch 24; Iteration 401; Loss 0.478087; Train Acc 0.706905; Val Acc 0.696061\n",
            "End of Epoch 24; Loss 0.546887; Train Acc 0.721113; Val Acc 0.700164\n",
            "Epoch 25; Iteration 1; Loss 0.576359; Train Acc 0.718529; Val Acc 0.696517\n",
            "Epoch 25; Iteration 101; Loss 0.536050; Train Acc 0.716293; Val Acc 0.698340\n",
            "Epoch 25; Iteration 201; Loss 0.643113; Train Acc 0.695848; Val Acc 0.673628\n",
            "Epoch 25; Iteration 301; Loss 0.539949; Train Acc 0.706811; Val Acc 0.689768\n",
            "Epoch 25; Iteration 401; Loss 0.517421; Train Acc 0.716261; Val Acc 0.699070\n",
            "End of Epoch 25; Loss 0.582223; Train Acc 0.714025; Val Acc 0.691410\n",
            "Epoch 26; Iteration 1; Loss 0.524203; Train Acc 0.707378; Val Acc 0.683111\n",
            "Epoch 26; Iteration 101; Loss 0.481848; Train Acc 0.706496; Val Acc 0.684115\n",
            "Epoch 26; Iteration 201; Loss 0.577485; Train Acc 0.723696; Val Acc 0.698340\n",
            "Epoch 26; Iteration 301; Loss 0.679102; Train Acc 0.713048; Val Acc 0.694237\n",
            "Epoch 26; Iteration 401; Loss 0.440154; Train Acc 0.722247; Val Acc 0.702353\n",
            "End of Epoch 26; Loss 0.517015; Train Acc 0.726153; Val Acc 0.706639\n",
            "Epoch 27; Iteration 1; Loss 0.509869; Train Acc 0.727067; Val Acc 0.704906\n",
            "Epoch 27; Iteration 101; Loss 0.451349; Train Acc 0.724735; Val Acc 0.703812\n",
            "Epoch 27; Iteration 201; Loss 0.648455; Train Acc 0.719695; Val Acc 0.700164\n",
            "Epoch 27; Iteration 301; Loss 0.557910; Train Acc 0.727130; Val Acc 0.702900\n",
            "Epoch 27; Iteration 401; Loss 0.594903; Train Acc 0.723664; Val Acc 0.699708\n",
            "End of Epoch 27; Loss 0.457097; Train Acc 0.724389; Val Acc 0.705362\n",
            "Epoch 28; Iteration 1; Loss 0.643565; Train Acc 0.724294; Val Acc 0.702991\n",
            "Epoch 28; Iteration 101; Loss 0.456519; Train Acc 0.685074; Val Acc 0.657213\n",
            "Epoch 28; Iteration 201; Loss 0.667213; Train Acc 0.727760; Val Acc 0.702535\n",
            "Epoch 28; Iteration 301; Loss 0.453182; Train Acc 0.729524; Val Acc 0.706365\n",
            "Epoch 28; Iteration 401; Loss 0.542677; Train Acc 0.731099; Val Acc 0.707551\n",
            "End of Epoch 28; Loss 0.527042; Train Acc 0.722562; Val Acc 0.691136\n",
            "Epoch 29; Iteration 1; Loss 0.548716; Train Acc 0.727854; Val Acc 0.695240\n",
            "Epoch 29; Iteration 101; Loss 0.453725; Train Acc 0.721333; Val Acc 0.697064\n",
            "Epoch 29; Iteration 201; Loss 0.448819; Train Acc 0.726153; Val Acc 0.699617\n",
            "Epoch 29; Iteration 301; Loss 0.639032; Train Acc 0.709457; Val Acc 0.690863\n",
            "Epoch 29; Iteration 401; Loss 0.500985; Train Acc 0.727224; Val Acc 0.702717\n",
            "End of Epoch 29; Loss 0.473864; Train Acc 0.728831; Val Acc 0.704541\n",
            "Epoch 30; Iteration 1; Loss 0.607605; Train Acc 0.728768; Val Acc 0.702626\n",
            "Epoch 30; Iteration 101; Loss 0.510908; Train Acc 0.726941; Val Acc 0.693507\n",
            "Epoch 30; Iteration 201; Loss 0.553454; Train Acc 0.719569; Val Acc 0.688401\n",
            "Epoch 30; Iteration 301; Loss 0.629995; Train Acc 0.735163; Val Acc 0.704815\n",
            "Epoch 30; Iteration 401; Loss 0.473323; Train Acc 0.731319; Val Acc 0.706730\n",
            "End of Epoch 30; Loss 0.516286; Train Acc 0.729933; Val Acc 0.697884\n",
            "Epoch 31; Iteration 1; Loss 0.513697; Train Acc 0.733650; Val Acc 0.705909\n",
            "Epoch 31; Iteration 101; Loss 0.753194; Train Acc 0.728232; Val Acc 0.695878\n",
            "Epoch 31; Iteration 201; Loss 0.427054; Train Acc 0.730721; Val Acc 0.701806\n",
            "Epoch 31; Iteration 301; Loss 0.586589; Train Acc 0.729807; Val Acc 0.697976\n",
            "Epoch 31; Iteration 401; Loss 0.524025; Train Acc 0.731319; Val Acc 0.700529\n",
            "End of Epoch 31; Loss 0.537422; Train Acc 0.726626; Val Acc 0.696152\n",
            "Epoch 32; Iteration 1; Loss 0.579777; Train Acc 0.730028; Val Acc 0.702262\n",
            "Epoch 32; Iteration 101; Loss 0.667320; Train Acc 0.723790; Val Acc 0.694146\n",
            "Epoch 32; Iteration 201; Loss 0.585489; Train Acc 0.725491; Val Acc 0.702535\n",
            "Epoch 32; Iteration 301; Loss 0.526198; Train Acc 0.732579; Val Acc 0.701532\n",
            "Epoch 32; Iteration 401; Loss 0.552119; Train Acc 0.719254; Val Acc 0.690771\n",
            "End of Epoch 32; Loss 0.416692; Train Acc 0.733209; Val Acc 0.700529\n",
            "Epoch 33; Iteration 1; Loss 0.565878; Train Acc 0.735289; Val Acc 0.702262\n",
            "Epoch 33; Iteration 101; Loss 0.523751; Train Acc 0.734879; Val Acc 0.704815\n",
            "Epoch 33; Iteration 201; Loss 0.548433; Train Acc 0.738785; Val Acc 0.706183\n",
            "Epoch 33; Iteration 301; Loss 0.493831; Train Acc 0.738281; Val Acc 0.702170\n",
            "Epoch 33; Iteration 401; Loss 0.558209; Train Acc 0.732453; Val Acc 0.696881\n",
            "End of Epoch 33; Loss 0.520107; Train Acc 0.728799; Val Acc 0.693598\n",
            "Epoch 34; Iteration 1; Loss 0.579928; Train Acc 0.728169; Val Acc 0.694784\n",
            "Epoch 34; Iteration 101; Loss 0.465945; Train Acc 0.711977; Val Acc 0.689951\n",
            "Epoch 34; Iteration 201; Loss 0.545072; Train Acc 0.740014; Val Acc 0.709192\n",
            "Epoch 34; Iteration 301; Loss 0.694972; Train Acc 0.723034; Val Acc 0.684570\n",
            "Epoch 34; Iteration 401; Loss 0.491610; Train Acc 0.732674; Val Acc 0.699435\n",
            "End of Epoch 34; Loss 0.504002; Train Acc 0.740329; Val Acc 0.705544\n",
            "Epoch 35; Iteration 1; Loss 0.513648; Train Acc 0.740171; Val Acc 0.706639\n",
            "Epoch 35; Iteration 101; Loss 0.520427; Train Acc 0.731193; Val Acc 0.692413\n",
            "Epoch 35; Iteration 201; Loss 0.531996; Train Acc 0.737588; Val Acc 0.700711\n",
            "Epoch 35; Iteration 301; Loss 0.538857; Train Acc 0.742124; Val Acc 0.706365\n",
            "Epoch 35; Iteration 401; Loss 0.474195; Train Acc 0.739982; Val Acc 0.704997\n",
            "End of Epoch 35; Loss 0.552834; Train Acc 0.740014; Val Acc 0.698887\n",
            "Epoch 36; Iteration 1; Loss 0.459759; Train Acc 0.738691; Val Acc 0.699161\n",
            "Epoch 36; Iteration 101; Loss 0.554762; Train Acc 0.738187; Val Acc 0.703356\n",
            "Epoch 36; Iteration 201; Loss 0.439818; Train Acc 0.721554; Val Acc 0.680923\n",
            "Epoch 36; Iteration 301; Loss 0.693381; Train Acc 0.684129; Val Acc 0.653474\n",
            "Epoch 36; Iteration 401; Loss 0.501748; Train Acc 0.739195; Val Acc 0.699982\n",
            "End of Epoch 36; Loss 0.637703; Train Acc 0.739573; Val Acc 0.697246\n",
            "Epoch 37; Iteration 1; Loss 0.585116; Train Acc 0.737273; Val Acc 0.696608\n",
            "Epoch 37; Iteration 101; Loss 0.628915; Train Acc 0.704259; Val Acc 0.671165\n",
            "Epoch 37; Iteration 201; Loss 0.470671; Train Acc 0.741400; Val Acc 0.698249\n",
            "Epoch 37; Iteration 301; Loss 0.431877; Train Acc 0.732044; Val Acc 0.695969\n",
            "Epoch 37; Iteration 401; Loss 0.521323; Train Acc 0.742975; Val Acc 0.699617\n",
            "End of Epoch 37; Loss 0.483703; Train Acc 0.744267; Val Acc 0.704541\n",
            "Epoch 38; Iteration 1; Loss 0.539003; Train Acc 0.736958; Val Acc 0.697884\n",
            "Epoch 38; Iteration 101; Loss 0.530812; Train Acc 0.746440; Val Acc 0.703082\n",
            "Epoch 38; Iteration 201; Loss 0.494971; Train Acc 0.742534; Val Acc 0.701441\n",
            "Epoch 38; Iteration 301; Loss 0.489762; Train Acc 0.749653; Val Acc 0.706730\n",
            "Epoch 38; Iteration 401; Loss 0.498918; Train Acc 0.704480; Val Acc 0.676181\n",
            "End of Epoch 38; Loss 0.521025; Train Acc 0.730469; Val Acc 0.694328\n",
            "Epoch 39; Iteration 1; Loss 0.610628; Train Acc 0.720105; Val Acc 0.690316\n",
            "Epoch 39; Iteration 101; Loss 0.507968; Train Acc 0.747826; Val Acc 0.701532\n",
            "Epoch 39; Iteration 201; Loss 0.518826; Train Acc 0.743731; Val Acc 0.696881\n",
            "Epoch 39; Iteration 301; Loss 0.468970; Train Acc 0.745527; Val Acc 0.704268\n",
            "Epoch 39; Iteration 401; Loss 0.526389; Train Acc 0.751071; Val Acc 0.705271\n",
            "End of Epoch 39; Loss 0.442888; Train Acc 0.751292; Val Acc 0.705636\n",
            "Epoch 40; Iteration 1; Loss 0.555511; Train Acc 0.751859; Val Acc 0.707003\n",
            "Epoch 40; Iteration 101; Loss 0.390092; Train Acc 0.749748; Val Acc 0.701350\n",
            "Epoch 40; Iteration 201; Loss 0.454741; Train Acc 0.725176; Val Acc 0.692504\n",
            "Epoch 40; Iteration 301; Loss 0.460083; Train Acc 0.753969; Val Acc 0.706183\n",
            "Epoch 40; Iteration 401; Loss 0.519333; Train Acc 0.737966; Val Acc 0.697155\n",
            "End of Epoch 40; Loss 0.552151; Train Acc 0.743920; Val Acc 0.697520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7002369668246445"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), \"model_sentimental.pth\")"
      ],
      "metadata": {
        "id": "jVNK9w_8e9-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TweetRNNM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(TweetRNNM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.emb = nn.Embedding.from_pretrained(glove.vectors)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        #self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "        self.uvect = [2*(torch.rand(hidden_size,1) - 0.5) for i in range(0,num_classes)] # \n",
        "        crb1 = crossbar(device_params)\n",
        "        # Can test using more than 1 crossbar linear layers.\n",
        "        # Easiest implementation is to create a crossbar for each linear layer\n",
        "        self.fc1 = Linear(hidden_size, num_classes,crb1,self.uvect)\n",
        "        self.fc1.use_cb(True)\n",
        "        #self.fc2 = nn.Linear(64*2*2, 10)\n",
        "        self.traincount = 0\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Look up the embedding\n",
        "        x = self.emb(x)\n",
        "        # Set an initial hidden state\n",
        "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
        "        # Forward propagate the RNN\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        # Pass the output of the last time step to the classifier\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc1(out.view(self.hidden_size, 1)).t()\n",
        "        out = F.log_softmax(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "sh1r6-jdfI_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('model_sentimental.pth')\n",
        "temp_model = TweetRNN(50, 100, 2)\n",
        "temp_model.load_state_dict(torch.load('model_sentimental.pth'))\n",
        "\n",
        "# from collections import OrderedDict\n",
        "# new_state_dict = OrderedDict()\n",
        "# for k, v in state_dict.items():\n",
        "#     name = k[7:] # remove `module.`\n",
        "#     new_state_dict[name] = v\n",
        "# # load params\n",
        "# temp_model.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfEiRx7gfRuf",
        "outputId": "399eb95a-18ef-4a2f-8c02-43d75c16af91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('model_sentimental.pth')\n",
        "model = TweetRNNM(50, 100, 2)\n",
        "model.load_state_dict(torch.load('model_sentimental.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "IF6N83rAfrLy",
        "outputId": "3cfe7838-abfb-4bbd-e889-a4bba93ea9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0a6ab6e0812f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_sentimental.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetRNNM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_sentimental.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1605\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TweetRNNM:\n\tMissing key(s) in state_dict: \"fc1.W\", \"fc1.b\". \n\tUnexpected key(s) in state_dict: \"fc.weight\", \"fc.bias\". "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# crossbar update\n",
        "device_params = {\"Vdd\": 1.8,\n",
        "                 \"r_wl\": 20,\n",
        "                 \"r_bl\": 20,\n",
        "                 \"m\": 200,\n",
        "                 \"n\": 200,\n",
        "                 \"r_on_mean\": 1e4,\n",
        "                 \"r_on_stddev\": 1e3,\n",
        "                 \"r_off_mean\": 1e5,\n",
        "                 \"r_off_stddev\": 1e4,\n",
        "                 \"dac_resolution\": 5,\n",
        "                 \"adc_resolution\": 8.3,\n",
        "                 \"device_resolution\": 6,\n",
        "                 \"bias_scheme\": 1/3,\n",
        "                 \"tile_rows\": 4,\n",
        "                 \"tile_cols\": 4,\n",
        "                 \"r_cmos_line\": 600,\n",
        "                 \"r_cmos_transistor\": 20, \n",
        "                 \"p_stuck_on\": 0.01,\n",
        "                 \"p_stuck_off\": 0.01}\n",
        "crb_new = crossbar(device_params)\n",
        "\n",
        "model.fc1.W = torch.nn.parameter.Parameter(temp_model.fc.weight.data)\n",
        "model.fc1.b = torch.nn.parameter.Parameter(temp_model.fc.bias.data)\n",
        "\n",
        "model.fc1.cb = crb_new\n",
        "model.fc1.remap()"
      ],
      "metadata": {
        "id": "gg2-pZhBfqhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_DDtfJtf8-U",
        "outputId": "1a001569-f415-40f3-d87e-0db48de16df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TweetRNNM(\n",
              "  (emb): Embedding(400000, 50)\n",
              "  (rnn): RNN(50, 100, batch_first=True)\n",
              "  (fc1): Linear()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def network_tester(model, test_loader, test_size, epoch, log = True):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            if batch_idx * len(data) > test_size:\n",
        "                break\n",
        "            output = model(data)\n",
        "\n",
        "            pred = output.data.max(1, keepdim=True)[1][0]\n",
        "            \n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "            total+=target.size(0)\n",
        "\n",
        "            if batch_idx % 1000 == 0 and log:\n",
        "              with open('log_baseline_test.csv', 'a') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([batch_idx + test_size * 100, test_loss/(batch_idx+1), correct.item()/total])\n",
        "              print(\"Epoch\", epoch, 'iteration',batch_idx, 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                          % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    return torch.div(correct, float(total))"
      ],
      "metadata": {
        "id": "XvNH7sK0gCDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testloader = torch.utils.data.DataLoader(test, batch_size=1, shuffle=True)\n",
        "network_tester(model, testloader, 9000, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V6-GN8bgLD7",
        "outputId": "008aa219-4a4e-4a44-9552-f301986b8a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iteration 0 Loss: 0.000 | Acc: 100.000% (1/1)\n",
            "Epoch 1 iteration 1000 Loss: 0.000 | Acc: 68.731% (688/1001)\n",
            "Epoch 1 iteration 2000 Loss: 0.000 | Acc: 68.466% (1370/2001)\n",
            "Epoch 1 iteration 3000 Loss: 0.000 | Acc: 69.110% (2074/3001)\n",
            "Epoch 1 iteration 4000 Loss: 0.000 | Acc: 69.458% (2779/4001)\n",
            "Epoch 1 iteration 5000 Loss: 0.000 | Acc: 69.086% (3455/5001)\n",
            "Epoch 1 iteration 6000 Loss: 0.000 | Acc: 69.522% (4172/6001)\n",
            "Epoch 1 iteration 7000 Loss: 0.000 | Acc: 69.761% (4884/7001)\n",
            "Epoch 1 iteration 8000 Loss: 0.000 | Acc: 69.654% (5573/8001)\n",
            "Epoch 1 iteration 9000 Loss: 0.000 | Acc: 69.737% (6277/9001)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6974)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}